Description: A master and pool of replicas for Ether Cattle

Parameters:
  DiskSize:
    Default: '250'
    Description: Size of each node's chaindata storage volume in GiB
    MaxValue: '1024'
    MinValue: '8'
    Type: Number
  ReplicaImageAMI:
    Default: ""
    Description: Custom AMI to use for the replica servers, empty string for default AWS AMI image
    Type: String
  ReplicaDiskType:
    AllowedValues:
    - standard
    - gp2
    - st1
    - sc1
    Default: gp2
    Description: Replica storage volume type
    Type: String
  ReplicaServeHTTP:
    Description: Enable replica to serve RPC over HTTP
    Type: String
    Default: 'true'
    AllowedValues:
    - 'true'
    - 'false'
  ReplicaServeGraphQL:
    Description: Enable replica to serve GraphQL over HTTP
    Type: String
    Default: 'true'
    AllowedValues:
    - 'true'
    - 'false'
  ReplicaServeWebsockets:
    Description: Enable replica to serve Websockets
    Type: String
    Default: 'true'
    AllowedValues:
    - 'true'
    - 'false'
  S3GethBucketName:
    Default: ethercattle-binaries
    Type: String
    Description: The bucket containing EtherCattle Geth Binaries
  ECGethVersion:
    Default: v1.9.5-2
    Type: String
    Description: The Ether Cattle Geth Version to deploys
  InfrastructureStack:
    Type: String
    Description: The infrastructure stack this cluster connects to
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: The name of the SSH key pair allowed to SSH into the nodes
  KafkaTopic:
    Type: String
    Description: A name for the Kafka Topic between the master and replicas. This must be unique for each cluster.
  NetworkId:
    Type: String
    Description: An identifier for the network this cluster represents. This should be common across all clusters representing the same network.
  SnapshotId:
    Type: String
    Description: A snapshot of the Ethereum folder with a synced blockchain
  MasterSize:
    Type: String
    Description: Whether to use full size masters or smaller ones. "full" will use a pool of large instances from the m5(ad) and r5(ad) families. "small" will use a pool of medium instances from the t3 and t3a families. For mainnet this must be full - for testnets and private networks it will depend on the network volume.
    AllowedValues:
      - full
      - small
    Default: full
  MasterCount:
    Type: Number
    Description: The number of Geth masters to run with the cluster. More masters means higher availability and that replicas are likely to be updated faster, but higher replica startup times and more disk usage.
    Default: 1
  MasterExtraFlags:
    Type: String
    Description: Extra flags for the Geth master (mainly for running other than mainnet)
  MasterMemoryThresholdLong:
    Type: Number
    Default: 75
    Description: The amount of memory which should trigger alarms if used for > 30 minutes
  MasterMemoryThresholdHigh:
    Type: Number
    Default: 85
    Description: The amount of memory which should trigger alarms if exceeded for > 1 minute
  ReplicaExtraFlags:
    Type: String
    Description: Extra flags for the Geth replica (mainly for running other than mainnet)
  ReplicaTargetCapacity:
    Type: Number
    Default: 2
    Description: Minimum number of instances for replicas
  ReplicaMaxCapacity:
    Type: Number
    Default: 5
    Description: Maximum number of instances for replicas
  ReplicaOnDemandPercentage:
    Type: Number
    Default: 0
    Description: The percentage (0 - 100) of replica that should be on-demand instead of spot instances.
  ReplicaCPUScalingTargetValue:
    Type: Number
    Default: 80
    Description: The percentage (0 - 100) CPU utilization target for auto scaling replicas
  ReplicaSize:
    Type: String
    Description: Whether to use full size replicas or smaller ones. "full" will use a pool of large instances from the m5d, m5ad, r5d, and r5ad families. "small" will use a pool of medium instances from the t3 and t3a families. Use "small" if you expect a small request volume.
    AllowedValues:
      - full
      - small
    Default: full
  MasterOnDemandPercentage:
    Type: Number
    Default: 50
    Description: The percentage (0 - 100) of masters that should be on-demand instead of spot instances.
  AlternateTargetGroup:
    Type: String
    Description: An alternative comma-separated list of target groups that replicas should be assigned to.
  NotificationEmail:
    Type: String
    Description: An optional e-mail address to receive notifications from alarms
  AlarmSNSTopic:
    Type: String
    Description: An optional SNS topic to receive notifications from alarms
  SnapshotValidationThreshold:
    Type: Number
    Default: 10000
    Description: The number of state trie nodes to validate when taking a snapshot.
  RemoteRPCURL:
    Type: String
    Description: A remote RPC URL to check against local block numbers. If provided, an alarm will go off if this cluster falls significantly behind the specified RPC endpoint. If not specified, an alarm will go off if no blocks are processed in a one minute period.
  ReplicaExtraSecurityGroup:
    Type: String
    Description: An additional security to be assigned to Replicas. Leave this blank unless you need to add additional connectivity rules.



Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Infrastructure
        Parameters:
          - InfrastructureStack
          - AlternateTargetGroup
          - AlarmSNSTopic
          - NotificationEmail
          - KeyName
          - RemoteRPCURL
      - Label:
          default: Cluster
        Parameters:
          - KafkaTopic
          - NetworkId
          - S3GethBucketName
          - ECGethVersion
          - SnapshotId
      - Label:
          default: Master
        Parameters:
          - MasterSize
          - MasterCount
          - MasterOnDemandPercentage
          - MasterExtraFlags
          - DiskSize
          - MasterMemoryThresholdLong
          - MasterMemoryThresholdHigh
      - Label:
          default: Replica
        Parameters:
          - ReplicaSize
          - ReplicaImageAMI
          - ReplicaServeHTTP
          - ReplicaServeGraphQL
          - ReplicaServeWebsockets
          - ReplicaExtraFlags
          - ReplicaDiskType
          - ReplicaTargetCapacity
          - ReplicaOnDemandPercentage
          - SnapshotValidationThreshold
          - ReplicaExtraSecurityGroup
    ParameterLabels:
      MasterSize:
        default: Master Size
      DiskSize:
        default: Disk Size
      ReplicaImageAMI:
        default: Replica AMI Image
      ReplicaServeHTTP:
        default: Enable Replica RPC HTTP server
      ReplicaServeGraphQL:
        default: Enable Replica GraphQL server
      ReplicaServeWebsockets:
        default: Enable Replica Websockets server
      ReplicaDiskType:
        default: Disk Type
      S3GethBucketName:
        default: S3 Geth Bucket
      ECGethVersion:
        default: Ether Cattle Geth Version Number
      InfrastructureStack:
        default: Infrastructure CloudFormation Stack
      KeyName:
        default: SSH Key Pair
      KafkaTopic:
        default: Unique Kafka Topic Name
      NetworkId:
        default: Unique Network ID
      SnapshotId:
        default: Chaindata Snapshot ID
      MasterCount:
        default: Master Count
      MasterExtraFlags:
        default: Extra Geth Flags
      ReplicaExtraFlags:
        default: Extra Geth Flags
      ReplicaTargetCapacity:
        default: Target Capacity
      ReplicaOnDemandPercentage:
        default: On-Demand Percentage
      ReplicaExtraSecurityGroup:
        default: Replica Extra Security Group
      AlternateTargetGroup:
        default: Alternate Target Group
      NotificationEmail:
        default: Notification Email Address
      AlarmSNSTopic:
        default: SNS Topic for Alarms
      SnapshotValidationThreshold:
        default: Snapshot Validation Threshold
      RemoteRPCURL:
        default: Remote RPC URL

Mappings:
  InstanceSizes:
    Master:
      full:
        - InstanceType: m5a.large
        - InstanceType: m5ad.large
        - InstanceType: m5.large
        - InstanceType: m5d.large
        - InstanceType: r5.large
        - InstanceType: r5d.large
        - InstanceType: r5a.large
        - InstanceType: r5ad.large
      small:
        - InstanceType: t3.medium
        - InstanceType: t3a.medium
    Replica:
      full:
        - InstanceType: m5ad.xlarge
        - InstanceType: m5d.xlarge
        - InstanceType: r5d.xlarge
        - InstanceType: r5ad.xlarge
        # - InstanceType: c5d.xlarge
        # - InstanceType: c5ad.2xlarge
      small:
        - InstanceType: t3.medium
        - InstanceType: t3a.medium
  PoolSize:
    Size:
      full: 11
      small: 6
  RegionMap:
    us-west-1:
      AL2AMI: ami-056ee704806822732
    eu-central-1:
      AL2AMI: ami-0cc293023f983ed53
    cn-north-1:
      AL2AMI: ami-0cad3dea07a7c36f9
    us-east-1:
      AL2AMI: ami-0b898040803850657
    ap-northeast-2:
      AL2AMI: ami-095ca789e0549777d
    us-gov-west1:
      AL2AMI:  ami-6b157f0a
    sa-east-1:
      AL2AMI: ami-058943e7d9b9cabfb
    ap-northeast-3:
      AL2AMI: ami-088d713d672ed235e
    ap-northeast-1:
      AL2AMI: ami-0c3fd0f5d33134a76
    ap-southeast-1:
      AL2AMI: ami-01f7527546b557442
    us-east-2:
      AL2AMI: ami-0d8f6eb4f641ef691
    ap-southeast-2:
      AL2AMI: ami-0dc96254d5535925f
    cn-northwest-1:
      AL2AMI: ami-094b7433620966eb5
    eu-west-1:
      AL2AMI: ami-0bbc25e23a7640b9b
    eu-north-1:
      AL2AMI: ami-d16fe6af
    us-gov-east1:
      AL2AMI: ami-1208ee63
    ap-south-1:
      AL2AMI: ami-0d2692b6acea72ee6
    eu-west-3:
      AL2AMI: ami-0adcddd3324248c4c
    eu-west-2:
      AL2AMI: ami-0d8e27447ec2c8410
    ca-central-1:
      AL2AMI: ami-0d4ae09ec9361d8ac
    us-west-2:
      AL2AMI: ami-082b5a644766e0e6f

Conditions:
  HasKeyName: !Not [!Equals [!Ref KeyName, '']]
  HasATG: !Not [!Equals [!Ref AlternateTargetGroup, '']]
  ReplicaHDD: !Or [!Equals [ !Ref ReplicaDiskType, "st1"], !Equals [ !Ref ReplicaDiskType, "sc1"]]
  SmallDisk: !Or [
      !Equals [ !Ref DiskSize, "75" ],
      !Equals [ !Ref DiskSize, "200" ],
      !Equals [ !Ref DiskSize, "250" ],
      !Equals [ !Ref DiskSize, "300" ],
      !Equals [ !Ref DiskSize, "350" ],
      !Equals [ !Ref DiskSize, "400" ],
      !Equals [ !Ref DiskSize, "450" ],
    ]
  HasNotificationEmail: !Not [!Equals [ !Ref NotificationEmail, "" ]]
  HasSNSTopic: !Not [!Equals [ !Ref AlarmSNSTopic, "" ]]
  HasReplicaHTTP: !Equals
    - !Ref ReplicaServeHTTP
    - 'true'
  HasReplicaGraphQL: !Equals
    - !Ref ReplicaServeGraphQL
    - 'true'
  HasReplicaWebsockets: !Equals
    - !Ref ReplicaServeWebsockets
    - 'true'
  HasReplicaImageAMI: !Not [!Equals [ !Ref ReplicaImageAMI, "" ]]
  HasRemoteRPCURL: !Not [!Equals [!Ref RemoteRPCURL, ""]]
  NoRemoteRPCURL: !Equals [ !Ref RemoteRPCURL, ""]
  HasExtraSecurityGroup: !Not [!Equals [ !Ref ReplicaExtraSecurityGroup, "" ]]
  SmallMaster: !Equals [ !Ref MasterSize, "small"]
  SmallReplica: !Equals [ !Ref ReplicaSize, "small"]

Resources:
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: "/"
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
  MulMin:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub |
          var response = require('cfn-response');
          exports.handler = function(event, context) {
            var result = parseInt(event.ResourceProperties.Op1) * parseInt(event.ResourceProperties.Op2);
            if(event.ResourceProperties.Max) {
              result = Math.min(result, parseInt(event.ResourceProperties.Max));
            }
            response.send(event, context, response.SUCCESS, {Value: result});
          };
      Runtime: nodejs8.10
  Max:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub |
          var response = require('cfn-response');
          exports.handler = function(event, context) {
            var result = Math.max(parseInt(event.ResourceProperties.Op1), parseInt(event.ResourceProperties.Op2));
            response.send(event, context, response.SUCCESS, {Value: result});
          };
      Runtime: nodejs8.10
  HDDSize:
    Type: Custom::Max
    Properties:
      ServiceToken: !GetAtt Max.Arn
      Op1: !Ref DiskSize
      Op2: 500
  VolumeIOPS:
    Type: Custom::MulMin
    Properties:
      ServiceToken: !GetAtt MulMin.Arn
      Op1: !Ref DiskSize
      Op2: 50
      Max: 5000
  MasterLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName:
        "Fn::Sub":
          - "/${ClusterId}/${AWS::StackName}/master"
          - ClusterId:
              "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
  MasterNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow internal SSH access and ETH p2p connectivity
      VpcId:
        "Fn::ImportValue": !Sub "${InfrastructureStack}-VpcId"
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: '22'
        ToPort: '22'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
      - IpProtocol: udp
        FromPort: '30303'
        ToPort: '30303'
        CidrIp: '0.0.0.0/0'
      - IpProtocol: tcp
        FromPort: '30303'
        ToPort: '30303'
        CidrIp: '0.0.0.0/0'
      - IpProtocol: udp
        FromPort: '30301'
        ToPort: '30301'
        CidrIp: '0.0.0.0/0'
  MasterNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  MasterNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref MasterNodeRole
      PolicyName: !Sub "MasterNode${KafkaTopic}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - logs:CreateLogStream
              - logs:CreateLogGroup
              - logs:PutLogEvents
            Effect: Allow
            Resource: "*"
            Sid: Stmt3
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource: !Sub arn:aws:s3:::${S3GethBucketName}/*
            Effect: Allow
          - Action:
              - cloudwatch:PutMetricData
              - ec2:DescribeTags
              - logs:PutLogEvents
              - logs:DescribeLogStreams
              - logs:DescribeLogGroups
              - logs:CreateLogStream
              - logs:CreateLogGroup
            Resource: "*"
            Effect: Allow
          - Action:
              - ssm:GetParameter
            Resource: !Sub "arn:aws:ssm:*:*:parameter/${MetricsConfigParameter}"
            Effect: Allow
          - Action:
              - ec2:ModifyVolume
              - ec2:DescribeVolumes
            Effect: Allow
            Resource: "*"
  MasterNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref MasterNodeRole
    DependsOn: MasterNodeRole
  MetricsConfigParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Type: String
      Value: '{"metrics":{"append_dimensions":{"AutoScalingGroupName":"${aws:AutoScalingGroupName}"},"metrics_collected":{"cpu":{"measurement":["cpu_usage_idle","cpu_usage_user","cpu_usage_system"],"metrics_collection_interval":60,"resources":["*"],"totalcpu":false},"disk":{"measurement":["used_percent","inodes_free"],"metrics_collection_interval":60,"resources":["/var/lib/ethereum","/var/lib/ethereum/overlay","/"]},"diskio":{"measurement":["io_time"],"metrics_collection_interval":60,"resources":["/var/lib/ethereum","/var/lib/ethereum/overlay","/"]},"mem":{"measurement":["mem_used_percent"],"metrics_collection_interval":60},"statsd":{"metrics_aggregation_interval":60,"metrics_collection_interval":10,"service_address":":8125"},"swap":{"measurement":["swap_used_percent"],"metrics_collection_interval":60}}}}'

  MasterLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", AL2AMI]
        InstanceType: m5.large
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Master"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Master"
        SecurityGroupIds:
          - !Sub ${MasterNodeSecurityGroup.GroupId}
        IamInstanceProfile:
          Name: !Ref MasterNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        CreditSpecification: !If [SmallMaster, {CpuCredits: standard}, !Ref 'AWS::NoValue']
        BlockDeviceMappings:
        - DeviceName: "/dev/xvda"
          Ebs:
            VolumeSize: 8
            VolumeType: gp2
        - DeviceName: "/dev/sdf"
          Ebs:
            VolumeSize: !Ref DiskSize
            VolumeType: io1
            Iops: !GetAtt VolumeIOPS.Value
            SnapshotId: !Ref SnapshotId
        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                GETH_BIN="geth-linux-$ARCH"
                LOGS_BIN="journald-cloudwatch-logs-$ARCH"
                aws s3 cp s3://${S3GethBucketName}/${ECGethVersion}/$GETH_BIN /usr/bin/geth
                aws s3 cp s3://${S3GethBucketName}/$LOGS_BIN /usr/local/bin/journald-cloudwatch-logs
                aws s3 cp s3://${S3GethBucketName}/peerManagerAuth.py /usr/local/bin/peerManager.py
                chmod +x /usr/bin/geth
                chmod +x /usr/local/bin/journald-cloudwatch-logs
                chmod +x /usr/local/bin/peerManager.py
                mkdir -p /var/lib/journald-cloudwatch-logs/
                mkdir -p /var/lib/ethereum
                mount -o barrier=0,data=writeback /dev/sdf /var/lib/ethereum
                resize2fs /dev/sdf
                useradd -r geth
                chown -R geth /var/lib/ethereum
                rm -f /var/lib/ethereum/geth/nodekey

                echo "/dev/sdf  /var/lib/ethereum    ext4   defaults,noatime  1   1" >> /etc/fstab

                yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/$ARCH/latest/amazon-cloudwatch-agent.rpm nmap-ncat jq python-pip

                pip install kafka-python

                /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:${MetricsConfigParameter} -s

                crontab -l >  newcrontab || true
                echo "5,20,35,50 * * * * /usr/bin/sh -c 'for x in \$(ls /dev/sd*) ; do echo resizing \$(readlink -f \$x) if needed; /usr/sbin/resize2fs \$(readlink -f \$x) ; done'" >> newcrontab
                crontab newcrontab

                printf "[Unit]\nDescription=Ethereum go client\nAfter=syslog.target network.target\n\n[Service]\nUser=geth\nGroup=geth\nEnvironment=HOME=/var/lib/ethereum\nType=simple\nExecStartPre=/usr/bin/geth replica ${ReplicaExtraFlags} --kafka.broker=${KafkaHostname} --datadir=/var/lib/ethereum --kafka.topic=${KafkaTopic} --replica.syncshutdown\nExecStart=/usr/bin/geth ${MasterExtraFlags} --light.maxpeers 0 --maxpeers 25 --gcmode=archive --kafka.broker=${KafkaHostname} --datadir=/var/lib/ethereum --kafka.topic=${KafkaTopic} --kafka.txpool.topic=${InfrastructureStack}-txpool\nKillMode=process\nKillSignal=SIGINT\nTimeoutStartSec=86400\nTimeoutStopSec=90\nOnFailure=poweroff.target\n\n[Install]\nWantedBy=multi-user.target\n" > /etc/systemd/system/geth.service

                printf "[Unit]\nDescription=Ethereum go client transaction relay\nAfter=syslog.target network.target geth\n\n[Service]\nUser=geth\nGroup=geth\nEnvironment=HOME=/var/lib/ethereum\nType=simple\nExecStart=/usr/bin/geth txrelay --kafka.broker=${KafkaHostname} --kafka.tx.topic=${NetworkId}-tx --kafka.tx.consumergroup=${KafkaTopic}-cg /var/lib/ethereum/geth.ipc\nKillMode=process\nKillSignal=SIGINT\nTimeoutStopSec=90\nRestart=on-failure\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\n" > /etc/systemd/system/geth-tx.service

                printf "[Unit]\nDescription=journald-cloudwatch-logs\nWants=basic.target\nAfter=basic.target network.target\n\n[Service]\nExecStart=/usr/local/bin/journald-cloudwatch-logs /usr/local/etc/journald-cloudwatch-logs.conf\nKillMode=process\nRestart=on-failure\nRestartSec=42s" > /etc/systemd/system/journald-cloudwatch-logs.service

                printf "log_group = \"${MasterLG}\"\nstate_file = \"/var/lib/journald-cloudwatch-logs/state\"" > /usr/local/etc/journald-cloudwatch-logs.conf

                printf "[Unit]\nDescription=Geth Peer Monitoring\nAfter=syslog.target network.target geth\n\n[Service]\nUser=geth\nGroup=geth\nEnvironment=HOME=/var/lib/ethereum\nType=simple\nExecStart=/usr/local/bin/peerManager.py /var/lib/ethereum/geth.ipc ${NetworkId}-peerlist ${KafkaHostname}\nKillMode=process\nKillSignal=SIGINT\nTimeoutStopSec=90\nRestart=on-failure\nRestartSec=10s\n" > /etc/systemd/system/geth-peer-data.service

                systemctl daemon-reload
                systemctl enable amazon-cloudwatch-agent.service
                systemctl start amazon-cloudwatch-agent.service
                systemctl enable journald-cloudwatch-logs
                systemctl start journald-cloudwatch-logs
                systemctl enable geth.service
                systemctl enable geth-tx.service
                systemctl enable geth-peer-data.service
                systemctl start geth.service
                sleep 5
                systemctl start geth-tx.service
                systemctl start geth-peer-data.service

                export AWS_DEFAULT_REGION=${AWS::Region}
                VOLUME_ID=$(aws ec2 describe-volumes --filters Name=attachment.instance-id,Values="$(curl http://169.254.169.254/latest/meta-data/instance-id)" | jq '.Volumes[] | select(. | .Attachments[0].Device == "/dev/sdf") | .VolumeId' -cr)
                sleep 1800 && aws ec2 modify-volume --volume-id $VOLUME_ID --volume-type gp2 &


              - KafkaHostname:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-KafkaBrokerURL"
                ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
                BaseInfrastructure:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-BaseInfrastructure"

  MasterAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      VPCZoneIdentifier:
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicA"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicB"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicC"
      # LaunchTemplate:
      #   LaunchTemplateId: !Ref MasterLaunchTemplate
      #   Version: !Sub ${MasterLaunchTemplate.LatestVersionNumber}
      MinSize: !Ref MasterCount
      MaxSize: 7
      HealthCheckType: EC2
      MixedInstancesPolicy:
        InstancesDistribution:
          OnDemandPercentageAboveBaseCapacity: !Ref MasterOnDemandPercentage
          SpotInstancePools: !FindInMap [PoolSize, Size, !Ref MasterSize]
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref MasterLaunchTemplate
            Version: !Sub ${MasterLaunchTemplate.LatestVersionNumber}
          Overrides: !FindInMap [InstanceSizes, Master, !Ref MasterSize]
      MetricsCollection:
      - Granularity: 1Minute
        Metrics:
        - GroupInServiceInstances
      Tags:
      - Key: Name
        Value: !Sub ${AWS::StackName}-Master
        PropagateAtLaunch: 'true'

  AggregatedNotifications:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Aggregated Notifications
  AggregatedNotificationsSubscription:
    Type: AWS::SNS::Subscription
    Condition: HasNotificationEmail
    Properties:
      Endpoint: !Ref NotificationEmail
      Protocol: email
      TopicArn: !Ref AggregatedNotifications
  ReplicaOverlayDiskSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Replica Overlay Disk
  ReplicaDiskOverlayAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref ReplicaOverlayDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the overlay data directory > 95% full"
      ComparisonOperator: "GreaterThanThreshold"
      Metrics:
        - Id: nvme
          MetricStat:
            Metric:
              MetricName: "disk_used_percent"
              Namespace: CWAgent
              Dimensions:
                - Name: AutoScalingGroupName
                  Value : !Ref ReplicaAutoScalingGroup
                - Name: device
                  Value : "nvme2n1"
                - Name: fstype
                  Value : "ext4"
                - Name: path
                  Value : "/var/lib/ethereum/overlay"
            Period: 60
            Stat: Maximum
          Label: NVME Overlay Volume Disk Usage
          ReturnData: false
        - Id: ebs
          MetricStat:
            Metric:
              MetricName: "disk_used_percent"
              Namespace: CWAgent
              Dimensions:
                - Name: AutoScalingGroupName
                  Value : !Ref ReplicaAutoScalingGroup
                - Name: device
                  Value : "nvme1n1"
                - Name: fstype
                  Value : "ext4"
                - Name: path
                  Value : "/var/lib/ethereum/overlay"
            Period: 60
            Stat: Maximum
          Label: EBS Overlay Disk Usage
          ReturnData: false
        - Id: delta
          Expression: "(ebs + nvme)"
      InsufficientDataActions:
        - !Ref ReplicaOverlayDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      OKActions:
        - !Ref ReplicaOverlayDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Threshold: 95
      TreatMissingData: missing
  MasterDiskSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master Disk
  MasterDiskAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the ethereum data directory > 95% full"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
        - Name: device
          Value : "nvme1n1"
        - Name: fstype
          Value : "ext4"
        - Name: path
          Value : "/var/lib/ethereum"
      InsufficientDataActions:
        - !Ref MasterDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "disk_used_percent"
      Namespace: CWAgent
      OKActions:
        - !Ref MasterDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 95
      TreatMissingData: missing
  MasterMemSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master RAM
  MasterMemAlarmLong:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: !Sub "Alarms when the master RAM > ${MasterMemoryThresholdLong} for 30 minutes"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 30
      DatapointsToAlarm: 28
      MetricName: "mem_used_percent"
      Namespace: CWAgent
      OKActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: !Ref MasterMemoryThresholdLong
      TreatMissingData: missing
  MasterMemAlarmHigh:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: !Sub "Alarms when the master RAM > ${MasterMemoryThresholdHigh} for 5 minutes%"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "mem_used_percent"
      Namespace: CWAgent
      OKActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: !Ref MasterMemoryThresholdHigh
      TreatMissingData: missing
  MasterCPUSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master RAM
  MasterCPUAlarmLong:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master CPU > 80%"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 30
      DatapointsToAlarm: 28
      MetricName: "CPUUtilization"
      Namespace: AWS/EC2
      OKActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 80
      TreatMissingData: missing
  MasterCPUAlarmHigh:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master CPU > 80%"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "CPUUtilization"
      Namespace: AWS/EC2
      OKActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 95
      TreatMissingData: missing
  MasterPeerCountSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master Peer Count
  MasterPeerCountAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterPeerCountSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master PeerCount < 10"
      ComparisonOperator: "LessThanThreshold"
      Dimensions:
        - Name: clusterId
          Value : !Ref KafkaTopic
      InsufficientDataActions:
        - !Ref MasterPeerCountSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "peerCount"
      Namespace: BlockData
      OKActions:
        - !Ref MasterPeerCountSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 10
      TreatMissingData: missing
  MasterLogMetricsFunctionLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName: !Join ["", ["/aws/lambda/", !Ref MasterLogMetricsFunction]]
  ReplicaLogMetricsFunctionLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName: !Join ["", ["/aws/lambda/", !Ref ReplicaLogMetricsFunction]]

  LogMetricsRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  LogMetricsFunctionPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref LogMetricsRole
      PolicyName: !Sub "MasterLogMetrics${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "logs:CreateLogStream"
              - "logs:PutLogEvents"
            Resource: "*"
          - Effect: Allow
            Action:
              - "cloudwatch:PutMetricData"
            Resource: "*"
          - Effect: Allow
            Action:
              - "logs:CreateLogGroup"
            Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
  MasterLogMetricsFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-12.zip
      Description: "A lambda function to process Geth logs into metrics"
      Environment:
        Variables:
          CLUSTER_ID: !Sub ${KafkaTopic}
      Handler: "logMonitor.masterHandler"
      Role: !Sub ${LogMetricsRole.Arn}
      Runtime: python3.7
  MasterLogMetricsSubscription:
    Type: AWS::Logs::SubscriptionFilter
    Properties:
      DestinationArn: !Sub ${MasterLogMetricsFunction.Arn}
      FilterPattern: '{$.systemdUnit = "geth.service" || $.systemdUnit = "geth-peer-data.service"}'
      LogGroupName: !Ref MasterLG
  MasterLogMetricFunctionInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${MasterLogMetricsFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: !Sub logs.${AWS::Region}.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub ${MasterLG.Arn}

  MasterBlockAgeSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Block Age
  MasterBlockAgeAlarm:
    Condition: NoRemoteRPCURL
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterBlockAgeSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the block age > 120"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: clusterId
          Value : !Ref KafkaTopic
      EvaluationPeriods: 3
      MetricName: "age"
      Namespace: BlockData
      OKActions:
        - !Ref MasterBlockAgeSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 30
      Statistic: Maximum
      Threshold: 120
      TreatMissingData: ignore

  MasterBlockNumberSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Block Number
  MasterBlockNumberAlarm:
    Type: AWS::CloudWatch::Alarm
    Condition: NoRemoteRPCURL
    Properties:
      AlarmActions:
        - !Ref MasterBlockNumberSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the block number is missing"
      ComparisonOperator: "LessThanThreshold"
      Dimensions:
        - Name: clusterId
          Value : !Ref KafkaTopic
      EvaluationPeriods: 3
      MetricName: "number"
      Namespace: BlockData
      OKActions:
        - !Ref MasterBlockNumberSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 30
      Statistic: SampleCount
      Threshold: 1
      TreatMissingData: breaching
  MasterBlockNumberComparisonAlarm:
    Type: AWS::CloudWatch::Alarm
    Condition: HasRemoteRPCURL
    Properties:
      AlarmActions:
        - !Ref MasterBlockNumberSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the block number is missing"
      ComparisonOperator: "GreaterThanThreshold"
      EvaluationPeriods: 2
      Metrics:
        - Id: remote
          MetricStat:
            Metric:
              MetricName: "RemoteBlockNumber"
              Namespace: BlockData
              Dimensions:
                - Name: provider
                  Value : !Ref RemoteRPCURL
            Period: 60
            Stat: Maximum
          Label: Remote Block Number
          ReturnData: false
        - Id: cluster
          MetricStat:
            Metric:
              MetricName: "number"
              Namespace: BlockData
              Dimensions:
                - Name: clusterId
                  Value : !Ref KafkaTopic
            Period: 60
            Stat: Maximum
          Label: Cluster Block Number
          ReturnData: false
        - Id: delta
          Expression: "(remote - cluster)"
      OKActions:
        - !Ref MasterBlockNumberSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Threshold: 1
      TreatMissingData: breaching

  ReplicaLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName:
        "Fn::Sub":
          - "/${ClusterId}/${AWS::StackName}/replica"
          - ClusterId:
              "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
  ReplicaNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow internal SSH access and VPC access to RPC
      VpcId:
        "Fn::ImportValue": !Sub "${InfrastructureStack}-VpcId"
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: '22'
        ToPort: '22'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
      - IpProtocol: tcp
        FromPort: '8545'
        ToPort: '8545'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
      - IpProtocol: tcp
        FromPort: '8546'
        ToPort: '8546'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
      - IpProtocol: tcp
        FromPort: '8547'
        ToPort: '8547'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
  ReplicaNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  ReplicaNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref ReplicaNodeRole
      PolicyName: !Sub "ReplicaNode${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - logs:CreateLogStream
              - logs:CreateLogGroup
              - logs:PutLogEvents
            Effect: Allow
            Resource: "*"
            Sid: Stmt3
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource: !Sub arn:aws:s3:::${S3GethBucketName}/*
            Effect: Allow
          - Action:
              - cloudwatch:PutMetricData
              - ec2:DescribeTags
              - logs:PutLogEvents
              - logs:DescribeLogStreams
              - logs:DescribeLogGroups
              - logs:CreateLogStream
              - logs:CreateLogGroup
            Resource: "*"
            Effect: Allow
          - Action:
              - ssm:GetParameter
            Resource: !Sub "arn:aws:ssm:*:*:parameter/${MetricsConfigParameter}"
            Effect: Allow
          - Action:
              - ec2:ModifyVolume
              - ec2:DescribeVolumes
            Effect: Allow
            Resource: "*"
  ReplicaNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref ReplicaNodeRole
    DependsOn: ReplicaNodeRole

  ReplicaLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: !If [HasReplicaImageAMI, !Ref ReplicaImageAMI, !FindInMap [RegionMap, !Ref "AWS::Region", AL2AMI]]
        InstanceType: m5ad.large
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Replica"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Replica"
        SecurityGroupIds:
          - !Sub ${ReplicaNodeSecurityGroup.GroupId}
          - !If [HasExtraSecurityGroup, !Ref ReplicaExtraSecurityGroup, !Ref 'AWS::NoValue']
        IamInstanceProfile:
          Name: !Ref ReplicaNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        CreditSpecification: !If [SmallReplica, {CpuCredits: standard}, !Ref 'AWS::NoValue']
        BlockDeviceMappings:
        - DeviceName: "/dev/xvda"
          Ebs:
            VolumeSize: 8
            VolumeType: gp2
        - DeviceName: "/dev/sdf"
          Ebs:
            VolumeSize: !If [ReplicaHDD, !GetAtt HDDSize.Value, !Ref DiskSize]
            VolumeType: !If [ReplicaHDD, !Ref ReplicaDiskType, "io1"]
            Iops: !If [ReplicaHDD, !Ref 'AWS::NoValue', !GetAtt VolumeIOPS.Value ]
            SnapshotId: !Ref SnapshotId
        - !If [ SmallReplica, {DeviceName: "/dev/sdg", Ebs: {VolumeSize: 25, VolumeType: gp2}}, !Ref 'AWS::NoValue']
        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                GETH_BIN="geth-linux-$ARCH"
                LOGS_BIN="journald-cloudwatch-logs-$ARCH"
                aws s3 cp s3://${S3GethBucketName}/${ECGethVersion}/$GETH_BIN /usr/bin/geth
                aws s3 cp s3://${S3GethBucketName}/$LOGS_BIN /usr/local/bin/journald-cloudwatch-logs
                chmod +x /usr/bin/geth
                chmod +x /usr/local/bin/journald-cloudwatch-logs
                mkdir -p /var/lib/journald-cloudwatch-logs/
                mkdir -p /var/lib/ethereum
                mount -o barrier=0,data=writeback /dev/sdf /var/lib/ethereum
                mkdir -p /var/lib/ethereum/overlay
                resize2fs /dev/sdf
                useradd -r geth

                echo "/dev/sdf  /var/lib/ethereum    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab

                if [ -e /dev/sdg ]
                then
                  mkfs.ext4 /dev/sdg
                  mount -o barrier=0,data=writeback /dev/sdg /var/lib/ethereum/overlay
                  echo "/dev/sdg  /var/lib/ethereum/overlay    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab
                  OVERLAY_FLAG="--datadir.overlay=/var/lib/ethereum/overlay"
                fi
                ignore="$(readlink -f /dev/sd*) $(readlink -f /dev/xvd*)"
                cutignore="$(for x in $ignore ; do echo $x | cut -c -12; done | uniq)"
                devices="$(ls /dev/nvme* | grep -E 'n1$')"
                cutdevices="$(for x in $devices ; do echo $x | cut -c -12; done | uniq)"
                localnvme=$(for d in $cutdevices; do if ! $(echo "$cutignore"| grep -q $d) ; then echo $d; fi ; done)
                if [ ! -z "$localnvme" ]
                then
                  mkfs.ext4 $localnvme
                  mount -o barrier=0,data=writeback $localnvme /var/lib/ethereum/overlay
                  echo "$localnvme  /var/lib/ethereum/overlay    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab
                  OVERLAY_FLAG="--datadir.overlay=/var/lib/ethereum/overlay"
                fi

                chown -R geth /var/lib/ethereum

                yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/$ARCH/latest/amazon-cloudwatch-agent.rpm jq fio || true


                /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:${MetricsConfigParameter} -s

                crontab -l >  newcrontab || true
                echo "5,20,35,50 * * * * /usr/bin/sh -c 'for x in \$(ls /dev/sd*) ; do echo resizing \$(readlink -f \$x) if needed; /usr/sbin/resize2fs \$(readlink -f \$x) ; done'" >> newcrontab
                crontab newcrontab

                printf "KafkaHostname=${KafkaHostname}\nKafkaTopic=${KafkaTopic}\nNetworkId=${NetworkId}\ninfraName=${InfrastructureStack}\nbaseInfraName=${BaseInfrastructure}\nnetwork=${NetworkId}" > /etc/systemd/system/ethcattle-vars

                SEP=$(echo "${KafkaHostname}" | grep -q "?" && echo "&" || echo "?")
                printf "[Unit]\nDescription=Ethereum go client replica\nAfter=syslog.target network.target\n[Service]\nUser=geth\nGroup=geth\nEnvironment=HOME=/var/lib/ethereum\nEnvironmentFile=/etc/systemd/system/ethcattle-vars\nType=simple\nLimitNOFILE=655360\nExecStartPre=/usr/bin/geth replica ${ReplicaExtraFlags} --kafka.broker=${KafkaHostname}""$SEP""fetch.default=8388608&max.waittime=25 --datadir=/var/lib/ethereum --kafka.topic=${KafkaTopic} --replica.syncshutdown\nExecStart=/usr/bin/bash -c '/usr/bin/geth replica ${ReplicaExtraFlags} $OVERLAY_FLAG --kafka.broker=\$KafkaHostname --datadir=/var/lib/ethereum --kafka.topic=\$KafkaTopic --kafka.txpool.topic=\$infraName-txpool  --kafka.tx.topic=\$NetworkId-tx --replica.startup.age=45 --replica.offset.age 62 ${ReplicaHTTPFlag} ${ReplicaGraphQLFlag} ${ReplicaWebsocketsFlag}'\nCPUSchedulingPolicy=fifo\nCPUSchedulingPriority=20\nKillMode=process\nKillSignal=SIGINT\nTimeoutStopSec=90\nRestart=on-failure\nTimeoutStartSec=86400\nRestartSec=10s\n[Install]\nWantedBy=multi-user.target\n" > /etc/systemd/system/geth.service

                printf "[Unit]\nDescription=journald-cloudwatch-logs\nWants=basic.target\nAfter=basic.target network.target\n\n[Service]\nExecStart=/usr/local/bin/journald-cloudwatch-logs /usr/local/etc/journald-cloudwatch-logs.conf\nKillMode=process\nRestart=on-failure\nRestartSec=42s" > /etc/systemd/system/journald-cloudwatch-logs.service

                printf "log_group = \"${ReplicaLG}\"\nstate_file = \"/var/lib/journald-cloudwatch-logs/state\"" > /usr/local/etc/journald-cloudwatch-logs.conf

                echo "geth        hard nofile 500000" >> /etc/security/limits.conf
                echo "geth        soft nofile 500000" >> /etc/security/limits.conf
                sysctl -w fs.file-max=12000500
                sysctl -w fs.nr_open=20000500
                # Set the maximum number of open file descriptors
                ulimit -n 20000000

                # Set the memory size for TCP with minimum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_mem='10000000 10000000 10000000'

                # Set the receive buffer for each TCP connection with minumum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_rmem='1024 4096 16384'

                # Set the TCP send buffer space with minumum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_wmem='1024 4096 16384'

                # The maximum socket receive buffer sizemem_max=16384
                sysctl -w net.core.rmem_max=16384

                # The maximum socket send buffer size
                sysctl -w net.core.wmem_max=16384

                sysctl -w vm.swappiness=0

                systemctl daemon-reload
                systemctl enable geth.service
                sleep 5 #TODO- workaround for a deadlock on topic creation
                rm /var/lib/ethereum/geth.ipc || true
                systemctl start geth.service || true &
                systemctl enable amazon-cloudwatch-agent.service
                systemctl start amazon-cloudwatch-agent.service
                systemctl enable journald-cloudwatch-logs
                systemctl start journald-cloudwatch-logs

                if [ -f /usr/bin/replica-hook ]
                then
                  /usr/bin/replica-hook
                fi
                export AWS_DEFAULT_REGION=${AWS::Region}
                fio --filename=/dev/sdf --rw=read --bs=128k --iodepth=32 --ioengine=libaio --direct=1 --name=volume-initialize &
                wait
                VOLUME_ID=$(aws ec2 describe-volumes --filters Name=attachment.instance-id,Values="$(curl http://169.254.169.254/latest/meta-data/instance-id)" | jq '.Volumes[] | select(. | .Attachments[0].Device == "/dev/sdf") | .VolumeId' -cr)
                aws ec2 modify-volume --volume-id $VOLUME_ID --volume-type gp2 &
              - KafkaHostname:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-KafkaBrokerURL"
                ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
                ReplicaHTTPFlag:
                    !If [HasReplicaHTTP, "--rpc --rpcaddr 0.0.0.0 --rpcport 8545", ""]
                ReplicaGraphQLFlag:
                    # Wow that's a lot of escaping!
                    !If [HasReplicaGraphQL, "--graphql --graphql.addr 0.0.0.0 --graphql.port 8547 --graphql.vhosts \\\\\\'*\\\\\\'", ""]
                ReplicaWebsocketsFlag:
                    !If [HasReplicaWebsockets, "--ws --wsaddr 0.0.0.0 --wsport 8546", ""]
                BaseInfrastructure:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-BaseInfrastructure"

  ReplicaAutoScalingPolicy:
    Type: AWS::AutoScaling::ScalingPolicy
    Properties:
      # AdjustmentType: String
      AutoScalingGroupName: !Ref ReplicaAutoScalingGroup
      # Cooldown: 900
      EstimatedInstanceWarmup: 600
      # MetricAggregationType: String
      # MinAdjustmentMagnitude: Integer
      PolicyType: TargetTrackingScaling
      # ScalingAdjustment: Integer
      # StepAdjustments:
      #   - StepAdjustment
      TargetTrackingConfiguration:
        PredefinedMetricSpecification:
          PredefinedMetricType: ASGAverageCPUUtilization
        TargetValue: !Ref ReplicaCPUScalingTargetValue

  ReplicaAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      VPCZoneIdentifier:
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicA"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicB"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicC"
      MixedInstancesPolicy:
        InstancesDistribution:
          OnDemandPercentageAboveBaseCapacity: !Ref ReplicaOnDemandPercentage
          SpotInstancePools: !FindInMap [PoolSize, Size, !Ref ReplicaSize]
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref ReplicaLaunchTemplate
            Version: !Sub ${ReplicaLaunchTemplate.LatestVersionNumber}
          Overrides: !FindInMap [InstanceSizes, Replica, !Ref ReplicaSize]
      MinSize: !Ref ReplicaTargetCapacity
      MaxSize: !Ref ReplicaMaxCapacity
      HealthCheckType: EC2
      TargetGroupARNs: !Split [ ",", !If [HasATG, !Ref AlternateTargetGroup, {"Fn::ImportValue": !Sub "${InfrastructureStack}-ALBGroupList"}]]
      MetricsCollection:
      - Granularity: 1Minute
        Metrics:
        - GroupInServiceInstances
      Tags:
      - Key: Name
        Value: !Sub ${AWS::StackName}-Replica
        PropagateAtLaunch: 'true'


  ReplicaLogMetricsFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-12.zip
      Description: "A lambda function to process Geth logs into metrics"
      Environment:
        Variables:
          CLUSTER_ID: !Sub ${KafkaTopic}
      Handler: "logMonitor.replicaHandler"
      Role: !Sub ${LogMetricsRole.Arn}
      Runtime: python3.7
  ReplicaLogMetricsSubscription:
    Type: AWS::Logs::SubscriptionFilter
    Properties:
      DestinationArn: !Sub ${ReplicaLogMetricsFunction.Arn}
      FilterPattern: '{$.systemdUnit = "geth.service"}'
      LogGroupName: !Ref ReplicaLG
  ReplicaLogMetricFunctionInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${ReplicaLogMetricsFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: !Sub logs.${AWS::Region}.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub ${ReplicaLG.Arn}


  SnapshotterLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: !If [HasReplicaImageAMI, !Ref ReplicaImageAMI, !FindInMap [RegionMap, !Ref "AWS::Region", AL2AMI]]
        InstanceType: m5a.large
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Snapshotter"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Snapshotter"
        SecurityGroupIds:
          - !Sub ${ReplicaNodeSecurityGroup.GroupId}
        IamInstanceProfile:
          Name: !Ref SnapshotterNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        # CreditSpecification:
        #   CpuCredits: standard
        InstanceInitiatedShutdownBehavior: terminate
        BlockDeviceMappings:
        - DeviceName: "/dev/xvda"
          Ebs:
            VolumeSize: 8
            VolumeType: gp2
        - DeviceName: "/dev/sdf"
          Ebs:
            VolumeSize: !Ref DiskSize
            VolumeType: io1
            Iops: !GetAtt VolumeIOPS.Value
            SnapshotId: !Ref SnapshotId
        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                GETH_BIN="geth-linux-$ARCH"
                aws s3 cp s3://${S3GethBucketName}/${ECGethVersion}/$GETH_BIN /usr/bin/geth
                chmod +x /usr/bin/geth
                mkdir -p /var/lib/ethereum
                mount -o barrier=0,data=writeback /dev/nvme1n1 /var/lib/ethereum
                resize2fs /dev/nvme1n1
                useradd -r geth
                chown -R geth /var/lib/ethereum

                yum install -y jq

                export AWS_DEFAULT_REGION=${AWS::Region}
                printf "KafkaHostname=${KafkaHostname}\nKafkaTopic=${KafkaTopic}\nNetworkId=${NetworkId}\ninfraName=${InfrastructureStack}\n" > /etc/systemd/system/ethcattle-vars

                if [ -f /usr/bin/replica-snapshot-hook ]
                then
                  /usr/bin/replica-snapshot-hook
                fi

                SEP=$(echo "${KafkaHostname}" | grep -q "?" && echo "&" || echo "?")
                sudo -u geth /usr/bin/geth replica ${ReplicaExtraFlags} --kafka.broker=$(printf "${KafkaHostname}")""$SEP""fetch.default=8388608&max.waittime=25 --datadir=/var/lib/ethereum --kafka.topic=${KafkaTopic} --replica.syncshutdown
                if ! sudo -u geth /usr/bin/geth verifystatetrie --datadir=/var/lib/ethereum ${SnapshotValidationThreshold}
                then
                  if [ "${AggregatedNotifications}" != "" ]
                  then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - Bad State Trie" --message="State trie verification failed while taking snapshot for cluster '${KafkaTopic}'. No snapshot will be taken. This is probably unrecoverable, and you will need to deploy a new cluster from your last good snapshot (probably '${SnapshotId}')"
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                  then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - Bad State Trie" --message="State trie verification failed while taking snapshot for cluster '${KafkaTopic}'. No snapshot will be taken. This is probably unrecoverable, and you will need to deploy a new cluster from your last good snapshot (probably '${SnapshotId}')"
                  fi
                  exit poweroff
                fi
                VOLUME_ID=$(aws ec2 describe-volumes --filters Name=attachment.instance-id,Values="$(curl http://169.254.169.254/latest/meta-data/instance-id)" | jq '.Volumes[] | select(. | .Attachments[0].Device == "/dev/sdf") | .VolumeId' -cr)

                if [ "$VOLUME_ID" == "" ]
                then
                  if [ "${AggregatedNotifications}" != "" ]
                  then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - Volume Identification Failed" --message="The snapshotting process for ${KafkaTopic} failed to identify the attached volume. Could not take a snapshot."
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                  then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - Volume Identification Failed" --message="The snapshotting process for ${KafkaTopic} failed to identify the attached volume. Could not take a snapshot."
                  fi
                  exit poweroff
                fi

                SNAPSHOT_ID=`aws ec2 create-snapshot --volume-id $VOLUME_ID --tag-specification="ResourceType=snapshot,Tags=[{Key=cluster,Value=${KafkaTopic}},{Key=Name,Value=${KafkaTopic}-chaindata-$(date -Isecond -u)}]" | jq '.SnapshotId' -cr`
                echo "Waiting for snapshot to complete"
                while [ `aws ec2 describe-snapshots --filters=Name=snapshot-id,Values=$SNAPSHOT_ID | jq '.Snapshots[0].State' -cr` != "completed" ];
                do
                    sleep 10
                done

                # CFN will set any parameters we don't provide back to their default values,
                # so get all of the parameters, update SnapshotID, and update the stack with
                # the new parameters.
                PARAMETERS=$(aws cloudformation describe-stacks --stack-name ${AWS::StackName} | jq '.Stacks[0].Parameters | map(if .ParameterKey == "SnapshotId" then .ParameterValue="'$SNAPSHOT_ID'" else . end)' -c)
                aws cloudformation update-stack --stack-name ${AWS::StackName} --use-previous-template --capabilities CAPABILITY_IAM --parameters="$PARAMETERS"

                # IF Day of week is Sunday, compact DB and re-update everything, after taking a new snapshot.
                if [ $(date +%u) = 7 ]; then
                  geth compactdb --datadir=/var/lib/ethereum
                  NEW_SNAPSHOT_ID=`aws ec2 create-snapshot --volume-id $VOLUME_ID --tag-specification="ResourceType=snapshot,Tags=[{Key=cluster,Value=${KafkaTopic}},{Key=Name,Value=${KafkaTopic}-chaindata-$(date -Isecond -u)}]" | jq '.SnapshotId' -cr`
                  echo "Waiting for snapshot to complete"
                  while [ `aws ec2 describe-snapshots --filters=Name=snapshot-id,Values=$NEW_SNAPSHOT_ID | jq '.Snapshots[0].State' -cr` != "completed" ];
                  do
                      sleep 10
                  done

                  # CFN will set any parameters we don't provide back to their default values,
                  # so get all of the parameters, update SnapshotID, and update the stack with
                  # the new parameters.
                  PARAMETERS=$(aws cloudformation describe-stacks --stack-name ${AWS::StackName} | jq '.Stacks[0].Parameters | map(if .ParameterKey == "SnapshotId" then .ParameterValue="'$NEW_SNAPSHOT_ID'" else . end)' -c)
                  aws cloudformation update-stack --stack-name ${AWS::StackName} --use-previous-template --capabilities CAPABILITY_IAM --parameters="$PARAMETERS"

                  #DELETE OLD SNAPSHOT ONCE EVERYTHING UPDATED
                  aws ec2 delete-snapshot --snapshot-id $SNAPSHOT_ID
                fi
                poweroff
              - KafkaHostname:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-KafkaBrokerURL"
                ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"

  SnapshotterNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  SnapshotterNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref SnapshotterNodeRole
      PolicyName: !Sub "SnapshotterNode${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - s3:GetObject
            Resource: !Sub arn:aws:s3:::${S3GethBucketName}/*
            Effect: Allow
          - Action:
              - cloudformation:UpdateStack
            Resource: !Sub "arn:aws:cloudformation:${AWS::Region}:${AWS::AccountId}:stack/${AWS::StackName}/*"
            Effect: Allow
          - Action:
              - iam:GetInstanceProfile
            Resource:
              - !Sub ${MasterNodeInstanceProfile.Arn}
              - !Sub ${ReplicaNodeInstanceProfile.Arn}
              - !Sub ${SnapshotterNodeInstanceProfile.Arn}
            Effect: Allow
          - Action:
              - lambda:UpdateFunctionConfiguration
              - lambda:GetFunctionConfiguration
            Resource:
              - !Sub ${SnapshotterLambdaFunction.Arn}
            Effect: Allow
          - Action:
              - iam:PassRole
              - iam:GetRole
              - iam:PutRolePolicy
            Resource:
              - !Sub "${ReplicaNodeRole.Arn}"
              - !Sub "${MasterNodeRole.Arn}"
              - !Sub "${SnapshotterLambdaRole.Arn}"
              - !Sub "${SnapshotterNodeRole.Arn}"
            Effect: Allow
          - Action:
              - sns:Publish
            Resource:
              - !Ref AggregatedNotifications
              - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
            Effect: Allow
          - Action:
              - autoscaling:EnableMetricsCollection
              - autoscaling:DisableMetricsCollection
              - autoscaling:UpdateAutoScalingGroup
            Resource:
              - "*"
            Condition:
              StringEquals:
                "autoscaling:ResourceTag/aws:cloudformation:stack-id": !Sub "${AWS::StackId}"
            Effect: Allow
          - Action:
              - cloudformation:DescribeStacks
              - ec2:DescribeLaunchTemplates
              - ec2:DescribeSnapshotAttribute
              - ec2:CreateTags
              - ec2:DescribeLaunchTemplateVersions
              - ec2:RunInstances
              - ec2:DescribeSnapshots
              - ec2:CreateLaunchTemplateVersion
              - ec2:DescribeVolumeStatus
              - autoscaling:DescribeAutoScalingGroups
              - autoscaling:DescribeScalingActivities
              - ec2:DescribeVolumes
              - ec2:CreateSnapshot
              - ec2:DeleteSnapshot
              - events:DescribeRule
              - ec2:DescribeKeyPairs
            Resource: "*"
            Effect: Allow
  SnapshotterNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref SnapshotterNodeRole
    DependsOn: SnapshotterNodeRole
  SnapshotterLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  SnapshotterLambdaPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref SnapshotterLambdaRole
      PolicyName: !Sub "SnapshotterLambdaPolicy${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - logs:CreateLogStream
              - logs:CreateLogGroup
              - logs:PutLogEvents
            Effect: Allow
            Resource: "*"
          - Effect: Allow
            Action:
              - iam:PassRole
            Resource: !Sub "${SnapshotterNodeRole.Arn}"
          - Effect: Allow
            Action:
              - ec2:CreateTags
              - ec2:RunInstances
            Resource:
              - Fn::Sub:
                - "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:subnet/${PublicA}"
                - PublicA:
                    "Fn::ImportValue":
                      !Sub "${InfrastructureStack}-PublicA"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:key-pair/${KeyName}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:instance/*"
              - !Sub "arn:aws:ec2:*::snapshot/${SnapshotId}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:volume/*"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:security-group/${ReplicaNodeSecurityGroup.GroupId}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:network-interface/*"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:launch-template/${SnapshotterLaunchTemplate}"
              - "arn:aws:ec2:*::image/*"

  SnapshotterLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-12.zip
      Description: "Launch instances to snapshot chaindata"
      Environment:
        Variables:
          LAUNCH_TEMPLATE_ID: !Ref SnapshotterLaunchTemplate
          LAUNCH_TEMPLATE_VERSION: !Sub "${SnapshotterLaunchTemplate.LatestVersionNumber}"
          SUBNET_ID:
            "Fn::ImportValue":
                !Sub "${InfrastructureStack}-PublicA"
          VOLUME_SIZE: !Ref DiskSize
      Handler: "getSnapshot.handler"
      Role: !Sub ${SnapshotterLambdaRole.Arn}
      Runtime: python3.7

  SnapshotSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub "Take a daily snapshot for the ${KafkaTopic} cluster"
      ScheduleExpression: "rate(1 day)"
      Targets:
        - Arn: !Sub ${SnapshotterLambdaFunction.Arn}
          Id: !Sub "snapshot-${KafkaTopic}"

  SnapshotterInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${SnapshotterLambdaFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${SnapshotSchedulerRule.Arn}


  SnapshotGCLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  SnapshotGCLambdaPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref SnapshotGCLambdaRole
      PolicyName: !Sub "SnapshotGCLambdaPolicy${AWS::StackName}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - ec2:DescribeSnapshots
              - ec2:DeleteSnapshot
            Resource: "*"

  SnapshotGCLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-12.zip
      Description: "Cleanup old chaindata snapshots"
      Environment:
        Variables:
          CLUSTER_ID: !Ref KafkaTopic
      Handler: "gcSnapshot.handler"
      Role: !Sub ${SnapshotGCLambdaRole.Arn}
      Runtime: python3.7

  SnapshotGCSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub "Cleanup old snapshots for the the ${KafkaTopic} cluster"
      ScheduleExpression: "rate(1 hour)"
      Targets:
        - Arn: !Sub ${SnapshotGCLambdaFunction.Arn}
          Id: !Sub "gc-${KafkaTopic}"

  SnapshotGCInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${SnapshotGCLambdaFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${SnapshotGCSchedulerRule.Arn}

  RemoteMetricsLambdaFunction:
    Condition: HasRemoteRPCURL
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-12.zip
      Description: "Collect metrics for remote RPC URLs"
      Environment:
        Variables:
          CLUSTER_ID: !Ref KafkaTopic
          RPC_URL: !Ref RemoteRPCURL
      Handler: "remote_metrics.handler"
      Role: !Sub ${LogMetricsRole.Arn}
      Runtime: python3.7

  RemoteMetricsSchedulerRule:
    Condition: HasRemoteRPCURL
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub ""
      ScheduleExpression: "rate(1 minute)"
      Targets:
        - Arn: !Sub ${RemoteMetricsLambdaFunction.Arn}
          Id: !Sub "remote-metrics-${KafkaTopic}"

  RemoteMetricsInvokePermission:
    Condition: HasRemoteRPCURL
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${RemoteMetricsLambdaFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${RemoteMetricsSchedulerRule.Arn}


  CloudwatchDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub "${AWS::StackName}"
      DashboardBody:
        Fn::Sub:
          - |
              {
                "widgets": [
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [ "BlockData", "number", "clusterId", "${KafkaTopic}", { "label": "Master Block Number" } ],
                                [ "ReplicaData", "num",  "clusterId", "${KafkaTopic}", { "stat": "Average", "label": "Replica Block Number (avg)" } ],
                                [ "ReplicaData", "num",  "clusterId", "${KafkaTopic}", { "stat": "Minimum", "label": "Replica Block Number (min)" } ]
                            ],
                            "view": "timeSeries",
                            "stacked": false,
                            "region": "${AWS::Region}",
                            "title": "Block Number"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 12,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "BlockData", "age", "clusterId", "${KafkaTopic}" ],
                                [ "ReplicaData", "age",  "clusterId", "${KafkaTopic}", { "stat": "Average", "label": "Replica Block Age (avg)" } ],
                                [ "ReplicaData", "age",  "clusterId", "${KafkaTopic}", { "stat": "Maximum", "label": "Replica Block Age (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Block Age"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 18,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "ReplicaData", "offsetAge", "clusterId", "${KafkaTopic}" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Offset Age"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "CWAgent", "disk_used_percent", "path", "/var/lib/ethereum", "AutoScalingGroupName", "${MasterAutoScalingGroup}", "device", "nvme1n1", "fstype", "ext4" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Disk Usage"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${MasterAutoScalingGroup}", { "stat": "Average", "label": "Master" }],
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}", { "stat": "Average", "label": "Replicas (avg)" } ],
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}", { "stat": "Maximum", "label": "Replicas (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "CPU Utilization"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [ { "expression": "m1-m2", "label": "Expression1", "id": "e1" } ],
                                [ "BlockData", "number", "clusterId", "${KafkaTopic}", { "id": "m1", "visible": false } ],
                                [ "ReplicaData", "num", "clusterId", "${KafkaTopic}", { "id": "m2", "visible": false } ]
                            ],
                            "view": "timeSeries",
                            "stacked": false,
                            "region": "${AWS::Region}",
                            "title": "Block Lag"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 12,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${MasterAutoScalingGroup}" , { "stat": "Average", "label": "Master" }],
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}" , { "stat": "Average", "label": "Replicas (avg)" } ],
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}" , { "stat": "Maximum", "label": "Replicas (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Memory Utilization"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 18,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [ "AWS/ApplicationELB", "RequestCountPerTarget", "TargetGroup", "${TargetGroup}", "LoadBalancer", "${LoadBalancer}", { "stat": "Sum", "period": 60 } ],
                                [ ".", "RequestCount", ".", "${TargetGroup}", ".", "${LoadBalancer}", { "stat": "Sum", "period": 60 } ]
                            ],
                            "view": "timeSeries",
                            "stacked": false,
                            "region": "${AWS::Region}",
                            "title": "Requests Per Replica",
                            "period": 300
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 12,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "AWS/ApplicationELB", "TargetResponseTime", "TargetGroup", "${TargetGroup}", "LoadBalancer", "${LoadBalancer}" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Response Time"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 12,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "BlockData", "peerCount", "clusterId", "${KafkaTopic}" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Master Peer Count"
                        }
                    }
                ]
              }
          - TargetGroup: {"Fn::ImportValue": !Sub "${InfrastructureStack}-RPCALBGroupName"}
            LoadBalancer: {"Fn::ImportValue": !Sub "${InfrastructureStack}-RPCALBName"}
