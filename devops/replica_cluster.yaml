Description: A master and pool of replicas for Ether Cattle

Parameters:
  MasterInstanceType:
    AllowedValues:
      - t2.micro
      - t3.micro
      - t2.small
      - t3.small
      - t2.medium
      - t3.medium
      - t2.large
      - t3.large
      - t2.xlarge
      - t3.xlarge
      - t2.2xlarge
      - t3.2xlarge
      - m4.large
      - m4.xlarge
      - m4.2xlarge
      - m4.4xlarge
      - m4.10xlarge
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.10xlarge
      - m5a.large
      - m5a.xlarge
      - m5a.2xlarge
      - m5a.4xlarge
      - m5a.10xlarge
      - m3.medium
      - m3.large
      - m3.xlarge
      - m3.2xlarge
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.8xlarge
      - c5d.large
      - c5d.xlarge
      - c5d.2xlarge
      - c5d.4xlarge
      - c5d.8xlarge
      - c4.large
      - c4.xlarge
      - c4.2xlarge
      - c4.4xlarge
      - c4.8xlarge
      - c3.large
      - c3.xlarge
      - c3.2xlarge
      - c3.4xlarge
      - c3.8xlarge
      - r3.large
      - r3.xlarge
      - r3.2xlarge
      - r3.4xlarge
      - r3.8xlarge
      - r4.large
      - r4.xlarge
      - r4.2xlarge
      - r4.4xlarge
      - r4.8xlarge
      - r4.16xlarge
      - i2.xlarge
      - i2.2xlarge
      - i2.4xlarge
      - i2.8xlarge
      - i3.large
      - i3.xlarge
      - i3.2xlarge
      - i3.4xlarge
      - i3.8xlarge
      - i3.16xlarge
    ConstraintDescription: Must be a valid EC2 HVM instance type.
    Default: m5a.large
    Description: EC2 HVM instance type (t2.micro, m3.medium, etc).
    Type: String
  DiskSize:
    Default: '250'
    Description: Size of each node's chaindata storage volume in GiB
    MaxValue: '1024'
    MinValue: '8'
    Type: Number
  ReplicaImageAMI:
    Default: ""
    Description: Custom AMI to use for the replica servers, empty string for default AWS AMI image
    Type: String
  ReplicaDiskType:
    AllowedValues:
    - standard
    - gp2
    - st1
    - sc1
    Default: gp2
    Description: Replica storage volume type
    Type: String
  ReplicaServeHTTP:
    Description: Enable replica to serve RPC over HTTP
    Type: String
    Default: 'true'
    AllowedValues:
    - 'true'
    - 'false'
  S3GethBucketName:
    Default: ethercattle-binaries
    Type: String
    Description: The bucket containing EtherCattle Geth Binaries
  ECGethVersion:
    Default: v1.9.0-2
    Type: String
    Description: The Ether Cattle Geth Version to deploys
  InfrastructureStack:
    Type: String
    Description: The infrastructure stack this cluster connects to
  KeyName:
    Type: AWS::EC2::KeyPair::KeyName
    Description: The name of the SSH key pair allowed to SSH into the nodes
  KafkaTopic:
    Type: String
    Description: A name for the Kafka Topic between the master and replicas. This must be unique for each cluster.
  NetworkId:
    Type: String
    Description: An identifier for the network this cluster represents. This should be common across all clusters representing the same network.
  SnapshotId:
    Type: String
    Description: A snapshot of the Ethereum folder with a synced blockchain
  MasterCount:
    Type: Number
    Description: The number of Geth masters to run with the cluster. More masters means higher availability and that replicas are likely to be updated faster, but higher replica startup times and more disk usage.
    Default: 1
  MasterExtraFlags:
    Type: String
    Description: Extra flags for the Geth master (mainly for running other than mainnet)
  ReplicaExtraFlags:
    Type: String
    Description: Extra flags for the Geth replica (mainly for running other than mainnet)
  ReplicaTargetCapacity:
    Type: Number
    Default: 2
    Description: Target number of instances for replicas
  ReplicaOnDemandPercentage:
    Type: Number
    Default: 0
    Description: The percentage (0 - 100) of replica that should be on-demand instead of spot instances.
  MasterOnDemandPercentage:
    Type: Number
    Default: 50
    Description: The percentage (0 - 100) of masters that should be on-demand instead of spot instances.
  ExternalTargetGroup:
    Type: String
    Description: Optional external target group to register replicas on
  UseStandardTargetGroup:
    Type: Number
    AllowedValues:
      - 0
      - 1
    Default: 1
    Description: Whether or not to connect replicas to the load balancer from the infrastructure stack
  NotificationEmail:
    Type: String
    Description: An optional e-mail address to receive notifications from alarms
  AlarmSNSTopic:
    Type: String
    Description: An optional SNS topic to receive notifications from alarms
  SnapshotValidationThreshold:
    Type: Number
    Default: 10000
    Description: The number of state trie nodes to validate when taking a snapshot.


Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
      - Label:
          default: Infrastructure
        Parameters:
          - InfrastructureStack
          - ExternalTargetGroup
          - UseStandardTargetGroup
          - AlarmSNSTopic
          - NotificationEmail
          - KeyName
      - Label:
          default: Cluster
        Parameters:
          - KafkaTopic
          - NetworkId
          - S3GethBucketName
          - ECGethVersion
          - SnapshotId
      - Label:
          default: Master
        Parameters:
          - MasterCount
          - MasterInstanceType
          - MasterOnDemandPercentage
          - MasterExtraFlags
          - DiskSize
      - Label:
          default: Replica
        Parameters:
          - ReplicaImageAMI
          - ReplicaServeHTTP
          - ReplicaExtraFlags
          - ReplicaDiskType
          - ReplicaTargetCapacity
          - ReplicaOnDemandPercentage
          - SnapshotValidationThreshold
    ParameterLabels:
      MasterInstanceType:
        default: Instance Type
      DiskSize:
        default: Disk Size
      ReplicaImageAMI:
        default: Replica AMI Image
      ReplicaServeHTTP:
        default: Enable Replica RPC HTTP server
      ReplicaDiskType:
        default: Disk Type
      S3GethBucketName:
        default: S3 Geth Bucket
      ECGethVersion:
        default: Ether Cattle Geth Version Number
      InfrastructureStack:
        default: Infrastructure CloudFormation Stack
      KeyName:
        default: SSH Key Pair
      KafkaTopic:
        default: Unique Kafka Topic Name
      NetworkId:
        default: Unique Network ID
      SnapshotId:
        default: Chaindata Snapshot ID
      MasterCount:
        default: Master Count
      MasterExtraFlags:
        default: Extra Geth Flags
      ReplicaExtraFlags:
        default: Extra Geth Flags
      ReplicaTargetCapacity:
        default: Target Capacity
      ReplicaOnDemandPercentage:
        default: On-Demand Percentage
      ExternalTargetGroup:
        default: External Target Group
      UseStandardTargetGroup:
        default: Use Standard Target Group
      NotificationEmail:
        default: Notification Email Address
      AlarmSNSTopic:
        default: SNS Topic for Alarms
      SnapshotValidationThreshold:
        default: Snapshot Validation Threshold

Mappings:
  RegionMap:
    us-west-1:
      AL2AMI: ami-056ee704806822732
    eu-central-1:
      AL2AMI: ami-0cc293023f983ed53
    cn-north-1:
      AL2AMI: ami-0cad3dea07a7c36f9
    us-east-1:
      AL2AMI: ami-0b898040803850657
    ap-northeast-2:
      AL2AMI: ami-095ca789e0549777d
    us-gov-west1:
      AL2AMI:  ami-6b157f0a
    sa-east-1:
      AL2AMI: ami-058943e7d9b9cabfb
    ap-northeast-3:
      AL2AMI: ami-088d713d672ed235e
    ap-northeast-1:
      AL2AMI: ami-0c3fd0f5d33134a76
    ap-southeast-1:
      AL2AMI: ami-01f7527546b557442
    us-east-2:
      AL2AMI: ami-0d8f6eb4f641ef691
    ap-southeast-2:
      AL2AMI: ami-0dc96254d5535925f
    cn-northwest-1:
      AL2AMI: ami-094b7433620966eb5
    eu-west-1:
      AL2AMI: ami-0bbc25e23a7640b9b
    eu-north-1:
      AL2AMI: ami-d16fe6af
    us-gov-east1:
      AL2AMI: ami-1208ee63
    ap-south-1:
      AL2AMI: ami-0d2692b6acea72ee6
    eu-west-3:
      AL2AMI: ami-0adcddd3324248c4c
    eu-west-2:
      AL2AMI: ami-0d8e27447ec2c8410
    ca-central-1:
      AL2AMI: ami-0d4ae09ec9361d8ac
    us-west-2:
      AL2AMI: ami-082b5a644766e0e6f

Conditions:
  HasKeyName: !Not [!Equals [!Ref KeyName, '']]
  UseSTG: !Equals [ !Ref UseStandardTargetGroup, 1]
  HasETG: !Not [!Equals [!Ref ExternalTargetGroup, '']]
  ReplicaHDD: !Or [!Equals [ !Ref ReplicaDiskType, "st1"], !Equals [ !Ref ReplicaDiskType, "sc1"]]
  SmallDisk: !Or [
      !Equals [ !Ref DiskSize, "75" ],
      !Equals [ !Ref DiskSize, "200" ],
      !Equals [ !Ref DiskSize, "250" ],
      !Equals [ !Ref DiskSize, "300" ],
      !Equals [ !Ref DiskSize, "350" ],
      !Equals [ !Ref DiskSize, "400" ],
      !Equals [ !Ref DiskSize, "450" ],
    ]
  HasNotificationEmail: !Not [!Equals [ !Ref NotificationEmail, "" ]]
  HasSNSTopic: !Not [!Equals [ !Ref AlarmSNSTopic, "" ]]
  HasReplicaHTTP: !Equals
    - !Ref ReplicaServeHTTP
    - 'true'
  HasReplicaImageAMI: !Not [!Equals [ !Ref ReplicaImageAMI, "" ]]

Resources:
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal: {Service: [lambda.amazonaws.com]}
          Action: ['sts:AssumeRole']
      Path: "/"
      ManagedPolicyArns:
      - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
  MulMin:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub |
          var response = require('cfn-response');
          exports.handler = function(event, context) {
            var result = parseInt(event.ResourceProperties.Op1) * parseInt(event.ResourceProperties.Op2);
            if(event.ResourceProperties.Max) {
              result = Math.min(result, parseInt(event.ResourceProperties.Max));
            }
            response.send(event, context, response.SUCCESS, {Value: result});
          };
      Runtime: nodejs8.10
  Max:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Code:
        ZipFile: !Sub |
          var response = require('cfn-response');
          exports.handler = function(event, context) {
            var result = Math.max(parseInt(event.ResourceProperties.Op1), parseInt(event.ResourceProperties.Op2));
            response.send(event, context, response.SUCCESS, {Value: result});
          };
      Runtime: nodejs8.10
  HDDSize:
    Type: Custom::Max
    Properties:
      ServiceToken: !GetAtt Max.Arn
      Op1: !Ref DiskSize
      Op2: 500
  VolumeIOPS:
    Type: Custom::MulMin
    Properties:
      ServiceToken: !GetAtt MulMin.Arn
      Op1: !Ref DiskSize
      Op2: 50
      Max: 5000
  MaxReplicas:
    Type: Custom::MulMin
    Properties:
      ServiceToken: !GetAtt MulMin.Arn
      Op1: !Ref ReplicaTargetCapacity
      Op2: 2
  MasterLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName:
        "Fn::Sub":
          - "/${ClusterId}/${KafkaTopic}/master"
          - ClusterId:
              "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
  MasterNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow internal SSH access and ETH p2p connectivity
      VpcId:
        "Fn::ImportValue": !Sub "${InfrastructureStack}-VpcId"
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: '22'
        ToPort: '22'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
      - IpProtocol: udp
        FromPort: '30303'
        ToPort: '30303'
        CidrIp: '0.0.0.0/0'
      - IpProtocol: tcp
        FromPort: '30303'
        ToPort: '30303'
        CidrIp: '0.0.0.0/0'
      - IpProtocol: udp
        FromPort: '30301'
        ToPort: '30301'
        CidrIp: '0.0.0.0/0'
  MasterNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  MasterNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref MasterNodeRole
      PolicyName: !Sub "MasterNode${KafkaTopic}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - logs:CreateLogStream
              - logs:CreateLogGroup
              - logs:PutLogEvents
            Effect: Allow
            Resource: "*"
            Sid: Stmt3
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource: !Sub arn:aws:s3:::${S3GethBucketName}/*
            Effect: Allow
          - Action:
              - cloudwatch:PutMetricData
              - ec2:DescribeTags
              - logs:PutLogEvents
              - logs:DescribeLogStreams
              - logs:DescribeLogGroups
              - logs:CreateLogStream
              - logs:CreateLogGroup
            Resource: "*"
            Effect: Allow
          - Action:
              - ssm:GetParameter
            Resource: !Sub "arn:aws:ssm:*:*:parameter/${MetricsConfigParameter}"
            Effect: Allow
          - Action:
              - ec2:ModifyVolume
              - ec2:DescribeVolumes
            Effect: Allow
            Resource: "*"
  MasterNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref MasterNodeRole
    DependsOn: MasterNodeRole
  MetricsConfigParameter:
    Type: "AWS::SSM::Parameter"
    Properties:
      Type: String
      Value: '{"metrics":{"append_dimensions":{"AutoScalingGroupName":"${aws:AutoScalingGroupName}"},"metrics_collected":{"cpu":{"measurement":["cpu_usage_idle","cpu_usage_iowait","cpu_usage_user","cpu_usage_system","cpu_usage_irq","cpu_usage_softirq"],"metrics_collection_interval":60,"resources":["*"],"totalcpu":false},"disk":{"measurement":["used_percent","inodes_free"],"metrics_collection_interval":60,"resources":["*"]},"diskio":{"measurement":["io_time"],"metrics_collection_interval":60,"resources":["*"]},"mem":{"measurement":["mem_used_percent"],"metrics_collection_interval":60},"statsd":{"metrics_aggregation_interval":60,"metrics_collection_interval":10,"service_address":":8125"},"swap":{"measurement":["swap_used_percent"],"metrics_collection_interval":60}}}}'

  MasterLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", AL2AMI]
        InstanceType: !Ref MasterInstanceType
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Master"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Master"
        SecurityGroupIds:
          - !Sub ${MasterNodeSecurityGroup.GroupId}
        IamInstanceProfile:
          Name: !Ref MasterNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        BlockDeviceMappings:
        - DeviceName: "/dev/xvda"
          Ebs:
            VolumeSize: 8
            VolumeType: gp2
        - DeviceName: "/dev/sdf"
          Ebs:
            VolumeSize: !Ref DiskSize
            VolumeType: io1
            Iops: !GetAtt VolumeIOPS.Value
            SnapshotId: !Ref SnapshotId
        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                GETH_BIN="geth-linux-$ARCH"
                LOGS_BIN="journald-cloudwatch-logs-$ARCH"
                aws s3 cp s3://${S3GethBucketName}/${ECGethVersion}/$GETH_BIN /usr/bin/geth
                aws s3 cp s3://${S3GethBucketName}/$LOGS_BIN /usr/local/bin/journald-cloudwatch-logs
                aws s3 cp s3://${S3GethBucketName}/peerManager.py /usr/local/bin/peerManager.py
                chmod +x /usr/bin/geth
                chmod +x /usr/local/bin/journald-cloudwatch-logs
                chmod +x /usr/local/bin/peerManager.py
                mkdir -p /var/lib/journald-cloudwatch-logs/
                mkdir -p /var/lib/ethereum
                mount -o barrier=0,data=writeback /dev/nvme1n1 /var/lib/ethereum
                resize2fs /dev/nvme1n1
                useradd -r geth
                chown -R geth /var/lib/ethereum
                rm -f /var/lib/ethereum/geth/nodekey

                echo "/dev/nvme1n1  /var/lib/ethereum    ext4   defaults,noatime  1   1" >> /etc/fstab

                yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/$ARCH/latest/amazon-cloudwatch-agent.rpm nmap-ncat jq python-pip

                pip install kafka-python

                /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:${MetricsConfigParameter} -s

                crontab -l >  newcrontab
                echo "5,20,35,50 * * * * sh -c 'for x in \$(ls /dev/sd*) ; do echo resizing \$(readlink -f \$x) if needed; resize2fs \$(readlink -f \$x) ; done'" >> newcrontab
                crontab newcrontab

                printf "[Unit]\nDescription=Ethereum go client\nAfter=syslog.target network.target\n\n[Service]\nUser=geth\nGroup=geth\nEnvironment=HOME=/var/lib/ethereum\nType=simple\nExecStartPre=/usr/bin/geth replica --kafka.broker=${KafkaHostname} --datadir=/var/lib/ethereum --kafka.topic=${KafkaTopic} --replica.syncshutdown\nExecStart=/usr/bin/geth ${MasterExtraFlags} --gcmode=archive --kafka.broker=${KafkaHostname} --datadir=/var/lib/ethereum --kafka.topic=${KafkaTopic}\nKillMode=process\nKillSignal=SIGINT\nTimeoutStartSec=86400\nTimeoutStopSec=90\nOnFailure=poweroff.target\n\n[Install]\nWantedBy=multi-user.target\n" > /etc/systemd/system/geth.service

                printf "[Unit]\nDescription=Ethereum go client transaction relay\nAfter=syslog.target network.target geth\n\n[Service]\nUser=geth\nGroup=geth\nEnvironment=HOME=/var/lib/ethereum\nType=simple\nExecStart=/usr/bin/geth txrelay --kafka.broker=${KafkaHostname} --kafka.tx.topic=${NetworkId}-tx --kafka.tx.consumergroup=${KafkaTopic}-cg /var/lib/ethereum/geth.ipc\nKillMode=process\nKillSignal=SIGINT\nTimeoutStopSec=90\nRestart=on-failure\nRestartSec=10s\n\n[Install]\nWantedBy=multi-user.target\n" > /etc/systemd/system/geth-tx.service

                printf "[Unit]\nDescription=journald-cloudwatch-logs\nWants=basic.target\nAfter=basic.target network.target\n\n[Service]\nExecStart=/usr/local/bin/journald-cloudwatch-logs /usr/local/etc/journald-cloudwatch-logs.conf\nKillMode=process\nRestart=on-failure\nRestartSec=42s" > /etc/systemd/system/journald-cloudwatch-logs.service

                printf "log_group = \"${MasterLG}\"\nstate_file = \"/var/lib/journald-cloudwatch-logs/state\"" > /usr/local/etc/journald-cloudwatch-logs.conf

                printf "[Unit]\nDescription=Geth Peer Monitoring\nAfter=syslog.target network.target geth\n\n[Service]\nUser=geth\nGroup=geth\nEnvironment=HOME=/var/lib/ethereum\nType=simple\nExecStart=/usr/local/bin/peerManager.py /var/lib/ethereum/geth.ipc ${NetworkId}-peerlist ${KafkaHostname}\nKillMode=process\nKillSignal=SIGINT\nTimeoutStopSec=90\nRestart=on-failure\nRestartSec=10s\n" > /etc/systemd/system/geth-peer-data.service

                systemctl daemon-reload
                systemctl enable amazon-cloudwatch-agent.service
                systemctl start amazon-cloudwatch-agent.service
                systemctl enable journald-cloudwatch-logs
                systemctl start journald-cloudwatch-logs
                systemctl enable geth.service
                systemctl enable geth-tx.service
                systemctl enable geth-peer-data.service
                systemctl start geth.service
                sleep 5
                systemctl start geth-tx.service
                systemctl start geth-peer-data.service

                export AWS_DEFAULT_REGION=${AWS::Region}
                VOLUME_ID=$(aws ec2 describe-volumes --filters Name=attachment.instance-id,Values="$(curl http://169.254.169.254/latest/meta-data/instance-id)" | jq '.Volumes[] | select(. | .Size > 50) | .VolumeId' -cr)
                sleep 1800 && aws ec2 modify-volume --volume-id $VOLUME_ID --volume-type gp2 &


              - KafkaHostname:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-Kafka2HostnameA"
                ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"

  MasterAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      VPCZoneIdentifier:
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicA"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicB"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicC"
      # LaunchTemplate:
      #   LaunchTemplateId: !Ref MasterLaunchTemplate
      #   Version: !Sub ${MasterLaunchTemplate.LatestVersionNumber}
      MinSize: 1
      MaxSize: 7
      DesiredCapacity: !Ref MasterCount
      HealthCheckType: EC2
      MixedInstancesPolicy:
        InstancesDistribution:
          OnDemandPercentageAboveBaseCapacity: !Ref MasterOnDemandPercentage
          SpotInstancePools: 11
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref MasterLaunchTemplate
            Version: !Sub ${MasterLaunchTemplate.LatestVersionNumber}
          Overrides:
            - InstanceType: m5a.large
            - InstanceType: m5ad.large
            - InstanceType: m5.large
            - InstanceType: m5d.large
            - InstanceType: r5.large
            - InstanceType: r5d.large
            - InstanceType: r5a.large
            - InstanceType: r5ad.large
      MetricsCollection:
      - Granularity: 1Minute
        Metrics:
        - GroupInServiceInstances
      Tags:
      - Key: Name
        Value: !Sub ${AWS::StackName}-Master
        PropagateAtLaunch: 'true'

  AggregatedNotifications:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Aggregated Notifications
  AggregatedNotificationsSubscription:
    Type: AWS::SNS::Subscription
    Condition: HasNotificationEmail
    Properties:
      Endpoint: !Ref NotificationEmail
      Protocol: email
      TopicArn: !Ref AggregatedNotifications
  ReplicaOverlayDiskSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Replica Overlay Disk
  ReplicaDiskOverlayAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref ReplicaOverlayDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the overlay data directory > 95% full"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref ReplicaAutoScalingGroup
        - Name: device
          Value : "nvme2n1"
        - Name: fstype
          Value : "ext4"
        - Name: path
          Value : "/var/lib/ethereum/overlay"
      InsufficientDataActions:
        - !Ref ReplicaOverlayDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "disk_used_percent"
      Namespace: CWAgent
      OKActions:
        - !Ref ReplicaOverlayDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 95
      TreatMissingData: missing
  MasterDiskSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master Disk
  MasterDiskAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the ethereum data directory > 95% full"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
        - Name: device
          Value : "nvme1n1"
        - Name: fstype
          Value : "ext4"
        - Name: path
          Value : "/var/lib/ethereum"
      InsufficientDataActions:
        - !Ref MasterDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "disk_used_percent"
      Namespace: CWAgent
      OKActions:
        - !Ref MasterDiskSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 95
      TreatMissingData: missing
  MasterMemSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master RAM
  MasterMemAlarmLong:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master RAM > 75% for 30 minutes"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 30
      MetricName: "mem_used_percent"
      Namespace: CWAgent
      OKActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 75
      TreatMissingData: missing
  MasterMemAlarmHigh:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master RAM > 85 for 5 minutes%"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "mem_used_percent"
      Namespace: CWAgent
      OKActions:
        - !Ref MasterMemSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 85
      TreatMissingData: missing
  MasterCPUSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master RAM
  MasterCPUAlarmLong:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master CPU > 80%"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 30
      MetricName: "CPUUtilization"
      Namespace: AWS/EC2
      OKActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 80
      TreatMissingData: missing
  MasterCPUAlarmHigh:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master CPU > 80%"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: AutoScalingGroupName
          Value : !Ref MasterAutoScalingGroup
      InsufficientDataActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "CPUUtilization"
      Namespace: AWS/EC2
      OKActions:
        - !Ref MasterCPUSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 95
      TreatMissingData: missing
  MasterPeerCountSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Master Peer Count
  MasterPeerCountAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterPeerCountSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the master PeerCount < 10"
      ComparisonOperator: "LessThanThreshold"
      Dimensions:
        - Name: clusterId
          Value : !Ref KafkaTopic
      InsufficientDataActions:
        - !Ref MasterPeerCountSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      EvaluationPeriods: 5
      MetricName: "peerCount"
      Namespace: BlockData
      OKActions:
        - !Ref MasterPeerCountSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 60
      Statistic: Maximum
      Threshold: 10
      TreatMissingData: missing
  MasterLogMetricsFunctionLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName: !Join ["", ["/aws/lambda/", !Ref MasterLogMetricsFunction]]
  ReplicaLogMetricsFunctionLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName: !Join ["", ["/aws/lambda/", !Ref ReplicaLogMetricsFunction]]

  LogMetricsRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  LogMetricsFunctionPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref LogMetricsRole
      PolicyName: !Sub "MasterLogMetrics${KafkaTopic}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - "logs:CreateLogStream"
              - "logs:PutLogEvents"
            Resource: "*"
          - Effect: Allow
            Action:
              - "cloudwatch:PutMetricData"
            Resource: "*"
          - Effect: Allow
            Action:
              - "logs:CreateLogGroup"
            Resource: !Sub "arn:aws:logs:${AWS::Region}:${AWS::AccountId}:*"
  MasterLogMetricsFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-7.zip
      Description: "A lambda function to process Geth logs into metrics"
      Environment:
        Variables:
          CLUSTER_ID: !Sub ${KafkaTopic}
      Handler: "logMonitor.masterHandler"
      Role: !Sub ${LogMetricsRole.Arn}
      Runtime: python3.7
  MasterLogMetricsSubscription:
    Type: AWS::Logs::SubscriptionFilter
    Properties:
      DestinationArn: !Sub ${MasterLogMetricsFunction.Arn}
      FilterPattern: '{$.systemdUnit = "geth.service" || $.systemdUnit = "geth-peer-data.service"}'
      LogGroupName: !Ref MasterLG
  MasterLogMetricFunctionInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${MasterLogMetricsFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: !Sub logs.${AWS::Region}.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub ${MasterLG.Arn}

  MasterBlockAgeSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Block Age
  MasterBlockAgeAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterBlockAgeSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the block age > 120"
      ComparisonOperator: "GreaterThanThreshold"
      Dimensions:
        - Name: clusterId
          Value : !Ref KafkaTopic
      EvaluationPeriods: 3
      MetricName: "age"
      Namespace: BlockData
      OKActions:
        - !Ref MasterBlockAgeSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 30
      Statistic: Maximum
      Threshold: 120
      TreatMissingData: ignore

  MasterBlockNumberSNS:
    Type: AWS::SNS::Topic
    Properties:
      DisplayName: Block Number
  MasterBlockNumberAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmActions:
        - !Ref MasterBlockNumberSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      AlarmDescription: "Alarms when the block number is missing"
      ComparisonOperator: "LessThanThreshold"
      Dimensions:
        - Name: clusterId
          Value : !Ref KafkaTopic
      EvaluationPeriods: 3
      MetricName: "number"
      Namespace: BlockData
      OKActions:
        - !Ref MasterBlockNumberSNS
        - !Ref AggregatedNotifications
        - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
      Period: 30
      Statistic: SampleCount
      Threshold: 1
      TreatMissingData: breaching

  ReplicaLG:
    Type: AWS::Logs::LogGroup
    Properties:
      RetentionInDays: 7
      LogGroupName:
        "Fn::Sub":
          - "/${ClusterId}/${KafkaTopic}/replica"
          - ClusterId:
              "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
  ReplicaNodeSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Allow internal SSH access and VPC access to RPC
      VpcId:
        "Fn::ImportValue": !Sub "${InfrastructureStack}-VpcId"
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: '22'
        ToPort: '22'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
      - IpProtocol: tcp
        FromPort: '8545'
        ToPort: '8545'
        CidrIp: !Join ["", ["Fn::ImportValue": !Sub "${InfrastructureStack}-VpcBaseIp", ".0.0/16"]]
  ReplicaNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  ReplicaNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref ReplicaNodeRole
      PolicyName: !Sub "ReplicaNode${KafkaTopic}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - logs:CreateLogStream
              - logs:CreateLogGroup
              - logs:PutLogEvents
            Effect: Allow
            Resource: "*"
            Sid: Stmt3
          - Action:
              - s3:GetObject
              - s3:ListBucket
              - s3:GetBucketPolicy
              - s3:GetObjectTagging
              - s3:GetBucketLocation
            Resource: !Sub arn:aws:s3:::${S3GethBucketName}/*
            Effect: Allow
          - Action:
              - cloudwatch:PutMetricData
              - ec2:DescribeTags
              - logs:PutLogEvents
              - logs:DescribeLogStreams
              - logs:DescribeLogGroups
              - logs:CreateLogStream
              - logs:CreateLogGroup
            Resource: "*"
            Effect: Allow
          - Action:
              - ssm:GetParameter
            Resource: !Sub "arn:aws:ssm:*:*:parameter/${MetricsConfigParameter}"
            Effect: Allow
  ReplicaNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref ReplicaNodeRole
    DependsOn: ReplicaNodeRole

  ReplicaLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: !If [HasReplicaImageAMI, !Ref ReplicaImageAMI, !FindInMap [RegionMap, !Ref "AWS::Region", AL2AMI]]
        InstanceType: m5ad.large
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Replica"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Replica"
        SecurityGroupIds:
          - !Sub ${ReplicaNodeSecurityGroup.GroupId}
        IamInstanceProfile:
          Name: !Ref ReplicaNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        BlockDeviceMappings:
        - DeviceName: "/dev/xvda"
          Ebs:
            VolumeSize: 8
            VolumeType: gp2
        - DeviceName: "/dev/sdf"
          Ebs:
            VolumeSize: !If [ReplicaHDD, !GetAtt HDDSize.Value, !Ref DiskSize]
            VolumeType: !Ref ReplicaDiskType
            SnapshotId: !Ref SnapshotId
        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                GETH_BIN="geth-linux-$ARCH"
                LOGS_BIN="journald-cloudwatch-logs-$ARCH"
                aws s3 cp s3://${S3GethBucketName}/${ECGethVersion}/$GETH_BIN /usr/bin/geth
                aws s3 cp s3://${S3GethBucketName}/$LOGS_BIN /usr/local/bin/journald-cloudwatch-logs
                chmod +x /usr/bin/geth
                chmod +x /usr/local/bin/journald-cloudwatch-logs
                mkdir -p /var/lib/journald-cloudwatch-logs/
                mkdir -p /var/lib/ethereum
                mount -o barrier=0,data=writeback /dev/nvme1n1 /var/lib/ethereum
                mkdir -p /var/lib/ethereum/overlay
                resize2fs /dev/nvme1n1
                useradd -r geth

                echo "/dev/nvme1n1  /var/lib/ethereum    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab

                if [ -e /dev/nvme2n1 ]
                then
                  mkfs.ext4 /dev/nvme2n1
                  mount -o barrier=0,data=writeback /dev/nvme2n1 /var/lib/ethereum/overlay
                  echo "/dev/nvme2n1  /var/lib/ethereum/overlay    ext4   barrier=0,data=writeback,noatime  1   1" >> /etc/fstab
                  OVERLAY_FLAG="--datadir.overlay=/var/lib/ethereum/overlay"
                fi
                chown -R geth /var/lib/ethereum

                yum install -y https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/$ARCH/latest/amazon-cloudwatch-agent.rpm || true

                /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c ssm:${MetricsConfigParameter} -s

                printf "KafkaHostname=${KafkaHostname}\nKafkaTopic=${KafkaTopic}\nNetworkId=${NetworkId}\ninfraName=${InfrastructureStack}\n" > /etc/systemd/system/ethcattle-vars

                printf "[Unit]\nDescription=Ethereum go client replica\nAfter=syslog.target network.target\n[Service]\nUser=geth\nGroup=geth\nEnvironmentHOME=/var/lib/ethereum\nEnvironmentFile=/etc/systemd/system/ethcattle-vars\nType=simple\nLimitNOFILE=655360\nExecStart=/usr/bin/bash -c '/usr/bin/geth replica ${ReplicaExtraFlags} $OVERLAY_FLAG --kafka.broker=\$KafkaHostname --datadir=/var/lib/ethereum --kafka.topic=\$KafkaTopic --kafka.tx.topic=\$NetworkId-tx --replica.startup.age=45 --replica.offset.age 62 --replica.block.age 240 ${ReplicaHTTPFlag}'\nKillMode=process\nKillSignal=SIGINT\nTimeoutStopSec=90\nRestart=on-failure\nRestartSec=10s\n[Install]\nWantedBy=multi-user.target\n" > /etc/systemd/system/geth.service

                printf "[Unit]\nDescription=journald-cloudwatch-logs\nWants=basic.target\nAfter=basic.target network.target\n\n[Service]\nExecStart=/usr/local/bin/journald-cloudwatch-logs /usr/local/etc/journald-cloudwatch-logs.conf\nKillMode=process\nRestart=on-failure\nRestartSec=42s" > /etc/systemd/system/journald-cloudwatch-logs.service

                printf "log_group = \"${ReplicaLG}\"\nstate_file = \"/var/lib/journald-cloudwatch-logs/state\"" > /usr/local/etc/journald-cloudwatch-logs.conf

                echo "geth        hard nofile 500000" >> /etc/security/limits.conf
                echo "geth        soft nofile 500000" >> /etc/security/limits.conf
                sysctl -w fs.file-max=12000500
                sysctl -w fs.nr_open=20000500
                # Set the maximum number of open file descriptors
                ulimit -n 20000000

                # Set the memory size for TCP with minimum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_mem='10000000 10000000 10000000'

                # Set the receive buffer for each TCP connection with minumum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_rmem='1024 4096 16384'

                # Set the TCP send buffer space with minumum, default and maximum thresholds
                sysctl -w net.ipv4.tcp_wmem='1024 4096 16384'

                # The maximum socket receive buffer sizemem_max=16384
                sysctl -w net.core.rmem_max=16384

                # The maximum socket send buffer size
                sysctl -w net.core.wmem_max=16384

                sysctl -w vm.swappiness=0

                systemctl daemon-reload
                systemctl enable geth.service
                sleep 5 #TODO- workaround for a deadlock on topic creation
                rm /var/lib/ethereum/geth.ipc || true
                systemctl start geth.service
                systemctl enable amazon-cloudwatch-agent.service
                systemctl start amazon-cloudwatch-agent.service
                systemctl enable journald-cloudwatch-logs
                systemctl start journald-cloudwatch-logs
              - KafkaHostname:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-Kafka2HostnameA"
                ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"
                ReplicaHTTPFlag:
                    !If [HasReplicaHTTP, "--rpc --rpcaddr 0.0.0.0 --rpcport 8545", ""]

  ReplicaAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      VPCZoneIdentifier:
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicA"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicB"
        - "Fn::ImportValue":
            !Sub "${InfrastructureStack}-PublicC"
      MixedInstancesPolicy:
        InstancesDistribution:
          OnDemandPercentageAboveBaseCapacity: !Ref ReplicaOnDemandPercentage
          SpotInstancePools: 11
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref ReplicaLaunchTemplate
            Version: !Sub ${ReplicaLaunchTemplate.LatestVersionNumber}
          Overrides:
            # - InstanceType: m5a.large
            - InstanceType: m5ad.large
            # - InstanceType: m5.large
            - InstanceType: m5d.large
            # - InstanceType: c5.large
            # - InstanceType: c5n.large
            # - InstanceType: c5d.large
            # - InstanceType: r5.large
            - InstanceType: r5d.large
            # - InstanceType: r5a.large
            - InstanceType: r5ad.large
      MinSize: 1
      MaxSize: !GetAtt MaxReplicas.Value
      DesiredCapacity: !Ref ReplicaTargetCapacity
      HealthCheckType: EC2
      TargetGroupARNs:
        - !If [UseSTG, {"Fn::ImportValue": !Sub "${InfrastructureStack}-RPCALBGroup"}, !Ref 'AWS::NoValue']
        - !If [HasETG, !Ref ExternalTargetGroup, !Ref 'AWS::NoValue']
      MetricsCollection:
      - Granularity: 1Minute
        Metrics:
        - GroupInServiceInstances
      Tags:
      - Key: Name
        Value: !Sub ${AWS::StackName}-Replica
        PropagateAtLaunch: 'true'


  ReplicaLogMetricsFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-7.zip
      Description: "A lambda function to process Geth logs into metrics"
      Environment:
        Variables:
          CLUSTER_ID: !Sub ${KafkaTopic}
      Handler: "logMonitor.replicaHandler"
      Role: !Sub ${LogMetricsRole.Arn}
      Runtime: python3.7
  ReplicaLogMetricsSubscription:
    Type: AWS::Logs::SubscriptionFilter
    Properties:
      DestinationArn: !Sub ${ReplicaLogMetricsFunction.Arn}
      FilterPattern: '{$.systemdUnit = "geth.service"}'
      LogGroupName: !Ref ReplicaLG
  ReplicaLogMetricFunctionInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${ReplicaLogMetricsFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: !Sub logs.${AWS::Region}.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub ${ReplicaLG.Arn}


  SnapshotterLaunchTemplate:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        ImageId: !If [HasReplicaImageAMI, !Ref ReplicaImageAMI, !FindInMap [RegionMap, !Ref "AWS::Region", AL2AMI]]
        InstanceType: m5a.large
        TagSpecifications:
          - ResourceType: instance
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Snapshotter"
          - ResourceType: volume
            Tags:
              - Key: Name
                Value: !Sub "${KafkaTopic}-Snapshotter"
        SecurityGroupIds:
          - !Sub ${ReplicaNodeSecurityGroup.GroupId}
        IamInstanceProfile:
          Name: !Ref SnapshotterNodeInstanceProfile
        KeyName: !If [HasKeyName, !Ref KeyName, !Ref 'AWS::NoValue']
        # CreditSpecification:
        #   CpuCredits: standard
        InstanceInitiatedShutdownBehavior: terminate
        BlockDeviceMappings:
        - DeviceName: "/dev/xvda"
          Ebs:
            VolumeSize: 8
            VolumeType: gp2
        - DeviceName: "/dev/sdf"
          Ebs:
            VolumeSize: !Ref DiskSize
            VolumeType: io1
            Iops: !GetAtt VolumeIOPS.Value
            SnapshotId: !Ref SnapshotId
        UserData:
          "Fn::Base64":
            "Fn::Sub":
              - |
                #!/bin/bash -xe
                if [ "$(arch)" == "x86_64" ]
                then
                  ARCH="amd64"
                elif [ "$(arch)" == "aarch64" ]
                then
                  ARCH="arm64"
                fi
                GETH_BIN="geth-linux-$ARCH"
                aws s3 cp s3://${S3GethBucketName}/${ECGethVersion}/$GETH_BIN /usr/bin/geth
                chmod +x /usr/bin/geth
                mkdir -p /var/lib/ethereum
                mount -o barrier=0,data=writeback /dev/nvme1n1 /var/lib/ethereum
                resize2fs /dev/nvme1n1
                useradd -r geth
                chown -R geth /var/lib/ethereum

                yum install -y jq

                export AWS_DEFAULT_REGION=${AWS::Region}
                printf "KafkaHostname=${KafkaHostname}\nKafkaTopic=${KafkaTopic}\nNetworkId=${NetworkId}\ninfraName=${InfrastructureStack}\n" > /etc/systemd/system/ethcattle-vars

                if [ -f /usr/bin/replca-hook ]
                then
                  /usr/bin/replica-snapshot-hook
                fi

                sudo -u geth /usr/bin/geth replica ${ReplicaExtraFlags} --kafka.broker=${KafkaHostname} --datadir=/var/lib/ethereum --kafka.topic=${KafkaTopic} --replica.syncshutdown
                if ! sudo -u geth /usr/bin/geth verifystatetrie --datadir=/var/lib/ethereum ${SnapshotValidationThreshold}
                then
                  if [ "${AggregatedNotifications}" != "" ]
                  then
                    aws sns publish --topic-arn=${AggregatedNotifications} --subject="${AWS::StackName} - Bad State Trie" --message="State trie verification failed while taking snapshot for cluster '${KafkaTopic}'. No snapshot will be taken. This is probably unrecoverable, and you will need to deploy a new cluster from your last good snapshot (probably '${SnapshotId}')"
                  fi
                  if [ "${AlarmSNSTopic}" != "" ]
                  then
                    aws sns publish --topic-arn=${AlarmSNSTopic} --subject="${AWS::StackName} - Bad State Trie" --message="State trie verification failed while taking snapshot for cluster '${KafkaTopic}'. No snapshot will be taken. This is probably unrecoverable, and you will need to deploy a new cluster from your last good snapshot (probably '${SnapshotId}')"
                  fi
                  exit poweroff
                fi
                VOLUME_ID=$(aws ec2 describe-volumes --filters Name=attachment.instance-id,Values="$(curl http://169.254.169.254/latest/meta-data/instance-id)" | jq '.Volumes[] | select(. | .Size > 50) | .VolumeId' -cr)

                SNAPSHOT_ID=`aws ec2 create-snapshot --volume-id $VOLUME_ID --tag-specification="ResourceType=snapshot,Tags=[{Key=cluster,Value=${KafkaTopic}},{Key=Name,Value=${KafkaTopic}-chaindata-$(date -Isecond -u)}]" | jq '.SnapshotId' -cr`
                echo "Waiting for snapshot to complete"
                while [ `aws ec2 describe-snapshots --filters=Name=snapshot-id,Values=$SNAPSHOT_ID | jq '.Snapshots[0].State' -cr` != "completed" ];
                do
                    sleep 10
                done

                # CFN will set any parameters we don't provide back to their default values,
                # so get all of the parameters, update SnapshotID, and update the stack with
                # the new parameters.
                PARAMETERS=$(aws cloudformation describe-stacks --stack-name ${AWS::StackName} | jq '.Stacks[0].Parameters | map(if .ParameterKey == "SnapshotId" then .ParameterValue="'$SNAPSHOT_ID'" else . end)' -c)
                aws cloudformation update-stack --stack-name ${AWS::StackName} --use-previous-template --capabilities CAPABILITY_IAM --parameters="$PARAMETERS"

                # IF Day of week is Sunday, compact DB and re-update everything, after taking a new snapshot.
                if [ $(date +%u) = 7 ]; then
                  geth compactdb --datadir=/var/lib/ethereum
                  NEW_SNAPSHOT_ID=`aws ec2 create-snapshot --volume-id $VOLUME_ID --tag-specification="ResourceType=snapshot,Tags=[{Key=cluster,Value=${KafkaTopic}},{Key=Name,Value=${KafkaTopic}-chaindata-$(date -Isecond -u)}]" | jq '.SnapshotId' -cr`
                  echo "Waiting for snapshot to complete"
                  while [ `aws ec2 describe-snapshots --filters=Name=snapshot-id,Values=$NEW_SNAPSHOT_ID | jq '.Snapshots[0].State' -cr` != "completed" ];
                  do
                      sleep 10
                  done

                  # CFN will set any parameters we don't provide back to their default values,
                  # so get all of the parameters, update SnapshotID, and update the stack with
                  # the new parameters.
                  PARAMETERS=$(aws cloudformation describe-stacks --stack-name ${AWS::StackName} | jq '.Stacks[0].Parameters | map(if .ParameterKey == "SnapshotId" then .ParameterValue="'$NEW_SNAPSHOT_ID'" else . end)' -c)
                  aws cloudformation update-stack --stack-name ${AWS::StackName} --use-previous-template --capabilities CAPABILITY_IAM --parameters="$PARAMETERS"

                  #DELETE OLD SNAPSHOT ONCE EVERYTHING UPDATED
                  aws ec2 delete-snapshot --snapshot-id $SNAPSHOT_ID
                fi
                poweroff
              - KafkaHostname:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-Kafka2HostnameA"
                ClusterId:
                  "Fn::ImportValue": !Sub "${InfrastructureStack}-ClusterId"

  SnapshotterNodeRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - ec2.amazonaws.com
            - autoscaling.amazonaws.com
        Version: '2012-10-17'
  SnapshotterNodePolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref SnapshotterNodeRole
      PolicyName: !Sub "SnapshotterNode${KafkaTopic}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action:
              - s3:GetObject
            Resource: !Sub arn:aws:s3:::${S3GethBucketName}/*
            Effect: Allow
          - Action:
              - cloudformation:UpdateStack
            Resource: !Sub "arn:aws:cloudformation:${AWS::Region}:${AWS::AccountId}:stack/${AWS::StackName}/*"
            Effect: Allow
          - Action:
              - iam:GetInstanceProfile
            Resource:
              - !Sub ${MasterNodeInstanceProfile.Arn}
              - !Sub ${ReplicaNodeInstanceProfile.Arn}
              - !Sub ${SnapshotterNodeInstanceProfile.Arn}
            Effect: Allow
          - Action:
              - lambda:UpdateFunctionConfiguration
              - lambda:GetFunctionConfiguration
            Resource:
              - !Sub ${SnapshotterLambdaFunction.Arn}
            Effect: Allow
          - Action:
              - iam:PassRole
              - iam:GetRole
              - iam:PutRolePolicy
            Resource:
              - !Sub "${ReplicaNodeRole.Arn}"
              - !Sub "${MasterNodeRole.Arn}"
              - !Sub "${SnapshotterLambdaRole.Arn}"
              - !Sub "${SnapshotterNodeRole.Arn}"
            Effect: Allow
          - Action:
              - sns:Publish
            Resource:
              - !Ref AggregatedNotifications
              - !If [ HasSNSTopic, !Ref AlarmSNSTopic,  !Ref 'AWS::NoValue']
            Effect: Allow
          - Action:
              - autoscaling:EnableMetricsCollection
              - autoscaling:DisableMetricsCollection
              - autoscaling:UpdateAutoScalingGroup
            Resource:
              - "*"
            Condition:
              StringEquals:
                "autoscaling:ResourceTag/aws:cloudformation:stack-id": !Sub "${AWS::StackId}"
            Effect: Allow
          - Action:
              - cloudformation:DescribeStacks
              - ec2:DescribeLaunchTemplates
              - ec2:DescribeSnapshotAttribute
              - ec2:CreateTags
              - ec2:DescribeLaunchTemplateVersions
              - ec2:RunInstances
              - ec2:DescribeSnapshots
              - ec2:CreateLaunchTemplateVersion
              - ec2:DescribeVolumeStatus
              - autoscaling:DescribeAutoScalingGroups
              - autoscaling:DescribeScalingActivities
              - ec2:DescribeVolumes
              - ec2:CreateSnapshot
              - ec2:DeleteSnapshot
              - events:DescribeRule
              - ec2:DescribeKeyPairs
            Resource: "*"
            Effect: Allow
  SnapshotterNodeInstanceProfile:
    Type: "AWS::IAM::InstanceProfile"
    Properties:
      Path: /
      Roles:
      - !Ref SnapshotterNodeRole
    DependsOn: SnapshotterNodeRole
  SnapshotterLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  SnapshotterLambdaPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref SnapshotterLambdaRole
      PolicyName: !Sub "SnapshotterLambdaPolicy${KafkaTopic}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - iam:PassRole
            Resource: !Sub "${SnapshotterNodeRole.Arn}"
          - Effect: Allow
            Action:
              - ec2:CreateTags
              - ec2:RunInstances
            Resource:
              - Fn::Sub:
                - "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:subnet/${PublicA}"
                - PublicA:
                    "Fn::ImportValue":
                      !Sub "${InfrastructureStack}-PublicA"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:key-pair/${KeyName}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:instance/*"
              - !Sub "arn:aws:ec2:*::snapshot/${SnapshotId}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:volume/*"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:security-group/${ReplicaNodeSecurityGroup.GroupId}"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:network-interface/*"
              - !Sub "arn:aws:ec2:${AWS::Region}:${AWS::AccountId}:launch-template/${SnapshotterLaunchTemplate}"
              - "arn:aws:ec2:*::image/*"

  SnapshotterLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-7.zip
      Description: "Launch instances to snapshot chaindata"
      Environment:
        Variables:
          LAUNCH_TEMPLATE_ID: !Ref SnapshotterLaunchTemplate
          LAUNCH_TEMPLATE_VERSION: !Sub "${SnapshotterLaunchTemplate.LatestVersionNumber}"
          SUBNET_ID:
            "Fn::ImportValue":
                !Sub "${InfrastructureStack}-PublicA"
          VOLUME_SIZE: !Ref DiskSize
      Handler: "getSnapshot.handler"
      Role: !Sub ${SnapshotterLambdaRole.Arn}
      Runtime: python3.7

  SnapshotSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub "Take a daily snapshot for the ${KafkaTopic} cluster"
      ScheduleExpression: "rate(1 day)"
      Targets:
        - Arn: !Sub ${SnapshotterLambdaFunction.Arn}
          Id: !Sub "snapshot-${KafkaTopic}"

  SnapshotterInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${SnapshotterLambdaFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${SnapshotSchedulerRule.Arn}


  SnapshotGCLambdaRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Action:
          - sts:AssumeRole
          Effect: Allow
          Principal:
            Service:
            - lambda.amazonaws.com
        Version: '2012-10-17'
  SnapshotGCLambdaPolicy:
    Type: "AWS::IAM::Policy"
    Properties:
      Roles:
        - !Ref SnapshotGCLambdaRole
      PolicyName: !Sub "SnapshotGCLambdaPolicy${KafkaTopic}"
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - ec2:DescribeSnapshots
              - ec2:DeleteSnapshot
            Resource: "*"

  SnapshotGCLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        S3Bucket: !Ref S3GethBucketName
        S3Key: lambdaPackage-7.zip
      Description: "Cleanup old chaindata snapshots"
      Environment:
        Variables:
          CLUSTER_ID: !Ref KafkaTopic
      Handler: "gcSnapshot.handler"
      Role: !Sub ${SnapshotGCLambdaRole.Arn}
      Runtime: python3.7

  SnapshotGCSchedulerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: !Sub "Cleanup old snapshots for the the ${KafkaTopic} cluster"
      ScheduleExpression: "rate(1 hour)"
      Targets:
        - Arn: !Sub ${SnapshotGCLambdaFunction.Arn}
          Id: !Sub "gc-${KafkaTopic}"

  SnapshotGCInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      FunctionName: !Sub ${SnapshotGCLambdaFunction.Arn}
      Action: 'lambda:InvokeFunction'
      Principal: events.amazonaws.com
      SourceArn: !Sub ${SnapshotGCSchedulerRule.Arn}


  CloudwatchDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub "${AWS::StackName}"
      DashboardBody:
        Fn::Sub:
          - |
              {
                "widgets": [
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [ "BlockData", "number", "clusterId", "${KafkaTopic}", { "label": "Master Block Number" } ],
                                [ "ReplicaData", "num",  "clusterId", "${KafkaTopic}", { "stat": "Average", "label": "Replica Block Number (avg)" } ],
                                [ "ReplicaData", "num",  "clusterId", "${KafkaTopic}", { "stat": "Minimum", "label": "Replica Block Number (min)" } ]
                            ],
                            "view": "timeSeries",
                            "stacked": false,
                            "region": "${AWS::Region}",
                            "title": "Block Number"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 12,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "BlockData", "age", "clusterId", "${KafkaTopic}" ],
                                [ "ReplicaData", "age",  "clusterId", "${KafkaTopic}", { "stat": "Average", "label": "Replica Block Age (avg)" } ],
                                [ "ReplicaData", "age",  "clusterId", "${KafkaTopic}", { "stat": "Maximum", "label": "Replica Block Age (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Block Age"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 18,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "ReplicaData", "offsetAge", "clusterId", "${KafkaTopic}" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Offset Age"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "CWAgent", "disk_used_percent", "path", "/var/lib/ethereum", "AutoScalingGroupName", "${MasterAutoScalingGroup}", "device", "nvme1n1", "fstype", "ext4" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Disk Usage"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${MasterAutoScalingGroup}", { "stat": "Average", "label": "Master" }],
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}", { "stat": "Average", "label": "Replicas (avg)" } ],
                                [ "AWS/EC2", "CPUUtilization", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}", { "stat": "Maximum", "label": "Replicas (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "CPU Utilization"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 0,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [ { "expression": "m1-m2", "label": "Expression1", "id": "e1" } ],
                                [ "BlockData", "number", "clusterId", "${KafkaTopic}", { "id": "m1", "visible": false } ],
                                [ "ReplicaData", "num", "clusterId", "${KafkaTopic}", { "id": "m2", "visible": false } ]
                            ],
                            "view": "timeSeries",
                            "stacked": false,
                            "region": "${AWS::Region}",
                            "title": "Block Lag"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 12,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${MasterAutoScalingGroup}" , { "stat": "Average", "label": "Master" }],
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}" , { "stat": "Average", "label": "Replicas (avg)" } ],
                                [ "CWAgent", "mem_used_percent", "AutoScalingGroupName", "${ReplicaAutoScalingGroup}" , { "stat": "Maximum", "label": "Replicas (max)" } ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Memory Utilization"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 18,
                        "y": 6,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "metrics": [
                                [ "AWS/ApplicationELB", "RequestCountPerTarget", "TargetGroup", "${TargetGroup}", "LoadBalancer", "${LoadBalancer}", { "stat": "Sum", "period": 60 } ],
                                [ ".", "RequestCount", ".", "${TargetGroup}", ".", "${LoadBalancer}", { "stat": "Sum", "period": 60 } ]
                            ],
                            "view": "timeSeries",
                            "stacked": false,
                            "region": "${AWS::Region}",
                            "title": "Requests Per Replica",
                            "period": 300
                        }
                    },
                    {
                        "type": "metric",
                        "x": 0,
                        "y": 12,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "AWS/ApplicationELB", "TargetResponseTime", "TargetGroup", "${TargetGroup}", "LoadBalancer", "${LoadBalancer}" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Response Time"
                        }
                    },
                    {
                        "type": "metric",
                        "x": 6,
                        "y": 12,
                        "width": 6,
                        "height": 6,
                        "properties": {
                            "view": "timeSeries",
                            "stacked": false,
                            "metrics": [
                                [ "BlockData", "peerCount", "clusterId", "${KafkaTopic}" ]
                            ],
                            "region": "${AWS::Region}",
                            "title": "Master Peer Count"
                        }
                    }
                ]
              }
          - TargetGroup: {"Fn::ImportValue": !Sub "${InfrastructureStack}-RPCALBGroupName"}
            LoadBalancer: {"Fn::ImportValue": !Sub "${InfrastructureStack}-RPCALBName"}
